

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" href="/img/favicon.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Dean0731">
  <meta name="keywords" content="">
  
    <meta name="description" content="Tensorflow2.0  Tensorflow 简介 Tensorflow是什么 Google开源软件库 采用数据流图,用于数值计算 支持多平台 GPU CPU 移动设备 最初用于深度学习,变得通用   数据流图 节点—处理数据 线—节点之间的输入输出关系 线上运输张量 节点被分配到各种计算设备上运行   特性 高度的灵活性 真正的可移植性 产品与科研结合 自动求微分 多语言支持 性能最优化">
<meta property="og:type" content="article">
<meta property="og:title" content="Dean0731&#39;s site">
<meta property="og:url" content="https://blog.dean0731.cn/2022/01/16/cnblog/Tensorflow2.0/index.html">
<meta property="og:site_name" content="Dean0731&#39;s site">
<meta property="og:description" content="Tensorflow2.0  Tensorflow 简介 Tensorflow是什么 Google开源软件库 采用数据流图,用于数值计算 支持多平台 GPU CPU 移动设备 最初用于深度学习,变得通用   数据流图 节点—处理数据 线—节点之间的输入输出关系 线上运输张量 节点被分配到各种计算设备上运行   特性 高度的灵活性 真正的可移植性 产品与科研结合 自动求微分 多语言支持 性能最优化">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://img2018.cnblogs.com/blog/1333782/201912/1333782-20191223172955331-1983219976.png">
<meta property="og:image" content="https://img2018.cnblogs.com/blog/1333782/201912/1333782-20191223173052716-1006708621.png">
<meta property="og:image" content="https://img2018.cnblogs.com/blog/1333782/201912/1333782-20191223173158408-1473862527.png">
<meta property="og:image" content="https://img2018.cnblogs.com/blog/1333782/201912/1333782-20191223173240250-502999884.png">
<meta property="og:image" content="https://img2018.cnblogs.com/blog/1333782/201912/1333782-20191223173305270-1255044464.png">
<meta property="article:published_time" content="2022-01-16T12:20:07.560Z">
<meta property="article:modified_time" content="2021-01-12T11:11:15.000Z">
<meta property="article:author" content="Dean0731">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://img2018.cnblogs.com/blog/1333782/201912/1333782-20191223172955331-1983219976.png">
  
  
  <title>Dean0731&#39;s site</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4/github-markdown.min.css" />
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hint.css@2/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.css" />
  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"blog.dean0731.cn","root":"/","version":"1.8.14","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 6.0.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Dean0731&#39; Site</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2022-01-16 20:20" pubdate>
        2022年1月16日 晚上
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      67k 字
    </span>
  

  
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      555 分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none"></h1>
            
            <div class="markdown-body">
              <p>Tensorflow2.0</p>
<ol>
<li><h1 id="Tensorflow-简介"><a href="#Tensorflow-简介" class="headerlink" title="Tensorflow 简介"></a>Tensorflow 简介</h1><ol>
<li><h3 id="Tensorflow是什么"><a href="#Tensorflow是什么" class="headerlink" title="Tensorflow是什么"></a>Tensorflow是什么</h3><ol>
<li><h4 id="Google开源软件库"><a href="#Google开源软件库" class="headerlink" title="Google开源软件库"></a>Google开源软件库</h4><ol>
<li>采用数据流图,用于数值计算</li>
<li>支持多平台 GPU CPU 移动设备</li>
<li>最初用于深度学习,变得通用</li>
</ol>
</li>
<li><h4 id="数据流图"><a href="#数据流图" class="headerlink" title="数据流图"></a>数据流图</h4><ol>
<li>节点—处理数据</li>
<li>线—节点之间的输入输出关系</li>
<li>线上运输张量</li>
<li>节点被分配到各种计算设备上运行</li>
</ol>
</li>
<li><h4 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h4><ol>
<li>高度的灵活性</li>
<li>真正的可移植性</li>
<li>产品与科研结合</li>
<li>自动求微分</li>
<li>多语言支持</li>
<li>性能最优化</li>
</ol>
</li>
</ol>
</li>
<li><h3 id="历史"><a href="#历史" class="headerlink" title="历史"></a>历史</h3><ol>
<li><h4 id="历史版本"><a href="#历史版本" class="headerlink" title="历史版本"></a>历史版本</h4><ol>
<li>2015年11月:首次发布</li>
<li>2015年12月:支持GPU python3.3(v0.6)</li>
<li>2016年4月:分布式tensorflow(v0.8)</li>
<li>2016年11月:支持windows(v0.11)</li>
<li>2017年2月:性能改进,API稳定性(v1.0)</li>
<li>2017年4月:Keras集成(v1.1)</li>
<li>2017年8月:高级API,预算估计器,更多模型,初始TPU支持(v1.3)</li>
<li>2017年11月:Eager execution和Tensorflow Lite(v1.5)</li>
<li>2018年3月:TF hub(与训练的库),Tensorflow.js Tensorflow Extended(TFX)</li>
<li>2018年5月:新入门内容 Cloud TPU模块与管道(v1.6)</li>
<li>2018年6月:新的分布式策略API:概率编程工具,Tensorflow Probability(v1.8)</li>
<li>2018年8月:Cloud Big Table 集成(v1.10)</li>
<li>2018年10月:侧重可用性的API改进(v1.12)</li>
<li>2019年:tensorflow2.0</li>
</ol>
</li>
<li><h4 id="Tensorflow1-0————–主要特性"><a href="#Tensorflow1-0————–主要特性" class="headerlink" title="Tensorflow1.0————–主要特性"></a>Tensorflow1.0————–主要特性</h4><ol>
<li>XLA:Accelerate Linear Algebra<ol>
<li>提升速度58倍</li>
<li>可以在移动设备运行</li>
</ol>
</li>
<li>引入更高级的API——-tf.layers/tf.metrics/tf.losses/tf.keras</li>
<li>Tensorflow 调试器</li>
<li>支持docker,引入tensorflow serving服务</li>
</ol>
</li>
<li><h4 id="Tensorflow1-0———————架构"><a href="#Tensorflow1-0———————架构" class="headerlink" title="Tensorflow1.0———————架构"></a>Tensorflow1.0———————架构</h4><p>Kears,Estimator,Datasets,Layers,Distribution engine</p>
<p><img src="https://img2018.cnblogs.com/blog/1333782/201912/1333782-20191223172955331-1983219976.png" srcset="/img/loading.gif" lazyload></p>
</li>
</ol>
</li>
</ol>
</li>
</ol>
<div class="code-wrapper"><pre><code class="hljs">  4. #### Tensorflow2.0----------------------主要特性

     1. 使用tf.keras和eager mode进行更加简单的模型构建
     2. 鲁棒的跨平台部署
     3. 强大的研究实验
     4. 清除了不推荐使用的API和减少了重复来简化PI

  5. #### Tensorflow2.0------------------------架构

     ![](https://img2018.cnblogs.com/blog/1333782/201912/1333782-20191223173009368-1172955030.png)


  6. #### Tensorflow2.0--------简化的模型开发流程

     1. 使用tf.data加载数据
     2. 使用tf.keras构建模型,也可以使用premade estimator来验证模型
        1. 使用tensorflow hub 进行迁移学习
     3. 使用eager mode 进行运行和调试
     4. 使用分发策略进行分布式训练
     5. 导出到SavedModel
     6. 使用Tensorflow Serve,Tensorflow  Lite,Tensorflow.js部署模型

  7. #### Tensorflow2.0-----------强大的跨平台能力

     1. Tensorflow服务
        1. 直接通过Http/REST或GRPC/协议缓冲区
     2. Tensorflow Lite----------可部署在Android ios和其他嵌入式设备
     3. Tensorflow.js------可在javascript中部署模型
     4. 其他语言
        1. c,java,go,c#等

  8. #### Tensorflow2.0------------强大的研究实现

     1. keras功能和子类API,允许创建一些复杂的拓扑结构
     2. 自定义训练逻辑,使用tf.GradientTape和tf.custom_gradient进行更细力度的控制
     3. 低层API自始至终可以与高层结合使用,完全的可定制
     4. 高级扩展:Ragged Tensors,Tensor2Tensor等
</code></pre></div>
<ol start="3">
<li><h3 id="Tensorflow-vs-Pytorch"><a href="#Tensorflow-vs-Pytorch" class="headerlink" title="Tensorflow vs Pytorch"></a>Tensorflow vs Pytorch</h3><ol>
<li><h4 id="入门时间"><a href="#入门时间" class="headerlink" title="入门时间"></a>入门时间</h4><ol>
<li><p>Tensorflow 1.*</p>
<ol>
<li>静态图</li>
<li>学习额外概念<ol>
<li>图,会话,变量,占位符等</li>
</ol>
</li>
<li>写样板代码</li>
</ol>
</li>
<li><p>Tensorflow 2.*</p>
<ol>
<li>动态图</li>
<li>Eager mode避免1.0缺点,直接集成在python中</li>
</ol>
</li>
<li><p>Pytorch</p>
<ol>
<li>动态图</li>
<li>Numpy的扩展,直接集成在python中</li>
</ol>
</li>
<li><p>静态图效率高,动态图容易调试</p>
</li>
<li><p>代码示例 1+$\frac{1}{2}$+ $\frac{1}{2^2}$+…..+$\frac{1}{2^{50}}$</p>
<ol>
<li><p>```python</p>
<h1 id="python"><a href="#python" class="headerlink" title="python"></a>python</h1><p>x = 0<br>y = 1<br>for iteration in range(50):</p>
<div class="code-wrapper"><pre><code class="hljs">x = x + y
y = y / 2
</code></pre></div>
<p>print(x)</p>
<figure class="highlight llvm"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></div></td><td class="code"><pre><code class="hljs llvm"><br><span class="hljs-number">2</span>. ```python<br>   # Pytorch<br>   import torch<br>   <span class="hljs-keyword">x</span> <span class="hljs-operator">=</span> tf.<span class="hljs-keyword">constant</span>(<span class="hljs-number">0</span>.)<br>   y <span class="hljs-operator">=</span> tf.<span class="hljs-keyword">constant</span>(<span class="hljs-number">1</span>.)<br>   for iteration in range(<span class="hljs-number">50</span>):<br>       <span class="hljs-keyword">x</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">x</span> + y<br>       y <span class="hljs-operator">=</span> y / <span class="hljs-number">2</span><br>   print(<span class="hljs-keyword">x</span>)<br></code></pre></td></tr></table></figure></li>
<li><p>```python</p>
<h1 id="tensorflow1"><a href="#tensorflow1" class="headerlink" title="tensorflow1.*"></a>tensorflow1.*</h1><p>import tensorflow as tf<br>x = tf.constant(0.)<br>y = tf.constant(1.)<br>add_op = x.assgin(x+y)<br>div_op = y.assgin(y/2)<br>with tf.Session() as sess:</p>
<div class="code-wrapper"><pre><code class="hljs">sess.run(tf.golbal_variables_initializers())
for iteration in range(50):
    sess.run(add_op)
    sess.run(dic_op)
 print(x.eval()) # sess.eval(x)
</code></pre></div>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs vim"><br><span class="hljs-number">4</span>. ```<span class="hljs-keyword">python</span><br>   # tensorflow2.*<br>   import tensorflow <span class="hljs-keyword">as</span> <span class="hljs-keyword">tf</span><br>   <span class="hljs-keyword">x</span> = <span class="hljs-keyword">tf</span>.constant(<span class="hljs-number">0</span>.)<br>   <span class="hljs-keyword">y</span> = <span class="hljs-keyword">tf</span>.constant(<span class="hljs-number">1</span>.)<br>   <span class="hljs-keyword">for</span> iteration in <span class="hljs-built_in">range</span>(<span class="hljs-number">50</span>)<br>   	<span class="hljs-keyword">x</span> = <span class="hljs-keyword">x</span> + <span class="hljs-keyword">y</span><br>       <span class="hljs-keyword">y</span> = <span class="hljs-keyword">y</span> / <span class="hljs-number">2</span><br>   <span class="hljs-keyword">print</span>(<span class="hljs-keyword">x</span>.numpy())<br></code></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
</li>
<li><h4 id="图创建和调试"><a href="#图创建和调试" class="headerlink" title="图创建和调试"></a>图创建和调试</h4><ol>
<li>Tensorflow 1.*<ol>
<li>静态图,难以调试,学习tfdbg调试</li>
</ol>
</li>
<li>Tensorflow 2.*与pytorch<ol>
<li>动态图,python自带的调试工具</li>
</ol>
</li>
</ol>
</li>
<li><h4 id="全面性"><a href="#全面性" class="headerlink" title="全面性"></a>全面性</h4><ol>
<li>Pythorch缺少<ol>
<li>沿维翻转张量(np.flip,np.flipud,np.fliplr)</li>
<li>检查无穷与非数值张量(np.is_nan,np.is_inf)</li>
<li>快速傅里叶变换(np.fft)</li>
</ol>
</li>
<li>随着时间变化,越来越接近</li>
</ol>
</li>
<li><h4 id="序列化和部署"><a href="#序列化和部署" class="headerlink" title="序列化和部署"></a>序列化和部署</h4><ol>
<li> Tensorflow支持更加广泛</li>
<li>图保存为protocol buffer</li>
<li>跨语言</li>
<li>跨平台</li>
<li>Pytorch支持比较简单</li>
</ol>
</li>
</ol>
</li>
<li><h3 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h3><ol>
<li><p>本地配置</p>
<ol>
<li>Virtualenv 安装或anaconda3</li>
<li>GPU环境配置</li>
</ol>
</li>
<li><p>云端配置</p>
<ol>
<li><p>为什么在云端配置</p>
<ol>
<li>规格统一,节省自己的机器</li>
<li>有直接配置好的镜像</li>
</ol>
</li>
<li><p>云环境</p>
<ol>
<li><p>Google Cloud,Amazon</p>
</li>
<li><p>实战</p>
<ol>
<li><p>从0配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs shell">            # ubuntu 18.04<br>            sudo apt-get install python3 # 安装python3<br>            sudo apt-get install python # 安装python3<br>            sudo apt-get install software-properties-common<br>            sudo apt-add-repository universe  # 奖pip所在源加入ubuntu<br>            sudo apt-get update<br>            sudo apt-get install python-pip<br>            sudo apt-get install python3-pip<br>            sudo pip3 install -U virtualenv # 或使用anaconda3<br>            # 创建虚拟环境<br>            mkdir environment &amp;&amp; cd environment<br>            virtualenv --system-site-packages -p python3 ./tf_py3<br>            source tf_py3/bin/activate # 激活环境<br>            pip install tensorflow<br>            # pip install tensorflow==2.0.0<br>            pip install numpy pandas matplotlib sklearn jupyter<br>            # 配置jupyter<br>            # 修改为静态ip配置,端口<br>            jupyter notebook --generate-config # 家目录生成配置文件 .jupyter<br>            c = get_config()<br>            c.NotebookApp.ip = &quot;*&quot;<br>            c.NotebookAPP.open_borwser = False<br>            c.NotebookAPP.post = 6006<br>            c.NotebookApp.allow_remote_access = True<br>            # 可使用token设置密码 供以后使用<br>            deactivate # 退出环境<br>            <br>            <br>            # 配置gpu环境<br>            # https://tensorflow.google.cn/install/gpu<br>            # 找到ubuntu18.04 复制为安装脚本执行即可<br>            # 可能会出现版本号不对应错误 libnvinfer-dev 将脚本中最后一条命令修改后运行libnvinfer-dev-5.1.5-1+cuda10.1 即可成功<br>            nvidia-smi # 查看GPU信息<br>            # tensorflow-gpu安装与cpu版类似<br>tf.test.is_gpu_available() # 判断gpu可用与否<br></code></pre></td></tr></table></figure></li>
<li><p>从镜像配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> 云端的系统镜像直接有开发环境</span><br><span class="hljs-meta">#</span><span class="bash"> 升级tensorflow 版本</span><br>pip install --upgrade tensorflow-gpu==2.0.0<br>pip3 install --upgrade tensorflow-gpu==2.0.0<br></code></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li><h1 id="Tensorflow-keras-实战"><a href="#Tensorflow-keras-实战" class="headerlink" title="Tensorflow keras 实战"></a>Tensorflow keras 实战</h1><ol>
<li><h3 id="keras是什么"><a href="#keras是什么" class="headerlink" title="keras是什么"></a>keras是什么</h3><ol>
<li>基于python的高级神经网络API</li>
<li>Francois Chollet2014-2015编写</li>
<li>以Tensorflow CNTK,或Theano为后端运行,keras必须有后端才可以<ol>
<li>后端可以切换,现在多用tensorflow</li>
</ol>
</li>
<li>及方便用于快速试验</li>
</ol>
</li>
<li><h3 id="tf-keras是什么"><a href="#tf-keras是什么" class="headerlink" title="tf.keras是什么"></a>tf.keras是什么</h3><ol>
<li>Tensorflow 对kerasAPI规范的实现</li>
<li>相对于tensorflow为后端的keras,Tensorflow-keras与tensorflow结合更紧密</li>
<li>实现在tf.keras下</li>
</ol>
</li>
<li><h3 id="Tf-keras与keras的"><a href="#Tf-keras与keras的" class="headerlink" title="Tf-keras与keras的"></a>Tf-keras与keras的</h3><ol>
<li><h4 id="联系"><a href="#联系" class="headerlink" title="联系"></a>联系</h4><ol>
<li>基于同一套API<ol>
<li>keras程序可转化为tf.keras</li>
<li>反之可能不成立,tf.keras有其它特性</li>
</ol>
</li>
<li>相同的JSON与hdf5模型序列化格式和语义</li>
</ol>
</li>
<li><h4 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h4><ol>
<li>Tf.keras全面支持eager mode<ol>
<li>只使用keras.Sequential和keras.Model时没影响</li>
<li>自定义Model内部运算逻辑时会有影响<ol>
<li>T低层API可以使用keras的model.fit等抽象法</li>
<li>适用于研究人员</li>
</ol>
</li>
</ol>
</li>
<li>Tf.keras支持基于tf.data的模型训练</li>
<li>Tf.keras支持TPU训练</li>
<li>Tf.keras支持tf.distribution中的分布式策略</li>
<li>其他特性<ol>
<li>Tf.keras可以与Tensorflow中的estimator集成</li>
<li>Tf.keras可以保存为SavedModel</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li><h3 id="知识点"><a href="#知识点" class="headerlink" title="知识点"></a>知识点</h3><ol>
<li><h4 id="分类问题与回归问题"><a href="#分类问题与回归问题" class="headerlink" title="分类问题与回归问题"></a>分类问题与回归问题</h4><ol>
<li>分类问题:输出类型是概率分布</li>
<li>回归问题:输出是一个是数值</li>
</ol>
</li>
<li><h4 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h4><ol>
<li><p>参数逐步调整</p>
</li>
<li><p>目标函数帮助衡量模型好坏</p>
</li>
<li><p>分类问题</p>
<ol>
<li><p>要衡量目标类别与当前预测的差距</p>
<ol>
<li>三分类问题输出:[0.2,0.7,0.1]</li>
<li>真是类别:2-&gt;ont_hot-&gt;[0,0,1]</li>
</ol>
</li>
<li><p>One_hot编码,把正整数变为向量表达</p>
<ol>
<li>生成一个长度不小于正整数的向量,只有正整数的位置处为1,其余位置都为0</li>
</ol>
</li>
<li><p>平方差损失<br>$$<br>\frac{1}{n} \sum_{x,y}\frac{1}{2}(y-Model(x))^2<br>$$</p>
</li>
<li><p>交叉熵损失<br>$$<br>\frac{1}{n}\sum_{x,y}yln(Model(x))<br>$$</p>
</li>
</ol>
</li>
<li><p>回归问题</p>
<ol>
<li>预测值与真实值的差距</li>
<li>平方差损失</li>
<li>绝对值损失</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li><h3 id="Tf框架-keras-回调函数"><a href="#Tf框架-keras-回调函数" class="headerlink" title="Tf框架:keras,回调函数"></a>Tf框架:keras,回调函数</h3><ol>
<li><h3 id="keras搭建模型"><a href="#keras搭建模型" class="headerlink" title="keras搭建模型"></a>keras搭建模型</h3><ol>
<li>```python<h1 id="coding-utf-8"><a href="#coding-utf-8" class="headerlink" title="coding:utf-8"></a>coding:utf-8</h1><h1 id="file-tf-keras-classification-model-py"><a href="#file-tf-keras-classification-model-py" class="headerlink" title="file: tf_keras_classification_model.py"></a>file: tf_keras_classification_model.py</h1><h1 id="author-Dean"><a href="#author-Dean" class="headerlink" title="author: Dean"></a>author: Dean</h1><h1 id="contact-x31-x30-x32-56-x39-x36-56-x39-x33-57-x40-113-113-46-99-x6f-x6d"><a href="#contact-x31-x30-x32-56-x39-x36-56-x39-x33-57-x40-113-113-46-99-x6f-x6d" class="headerlink" title="contact: &#x31;&#x30;&#x32;&#56;&#x39;&#x36;&#56;&#x39;&#x33;&#57;&#x40;&#113;&#113;&#46;&#99;&#x6f;&#x6d;"></a>contact: <a href="mailto:&#x31;&#x30;&#x32;&#56;&#x39;&#x36;&#56;&#x39;&#x33;&#57;&#x40;&#113;&#113;&#46;&#99;&#x6f;&#x6d;">&#x31;&#x30;&#x32;&#56;&#x39;&#x36;&#56;&#x39;&#x33;&#57;&#x40;&#113;&#113;&#46;&#99;&#x6f;&#x6d;</a></h1><h1 id="time-2019-12-17-11-47"><a href="#time-2019-12-17-11-47" class="headerlink" title="time: 2019/12/17 11:47"></a>time: 2019/12/17 11:47</h1><h1 id="desc-keras模型搭建"><a href="#desc-keras模型搭建" class="headerlink" title="desc: keras模型搭建"></a>desc: keras模型搭建</h1>import matplotlib as mpl<br>import matplotlib.pyplot as plt<br>import numpy as np<br>import sklearn<br>import pandas as pd<br>import os,sys,time<br>import tensorflow as tf<br>from tensorflow import keras<h1 id="import-keras"><a href="#import-keras" class="headerlink" title="import keras"></a>import keras</h1>def showVersion():<div class="code-wrapper"><pre><code class="hljs">print((tf.__version__))
print(sys.version_info)
for module in mpl, np, pd, sklearn, tf, keras:
    print(module.__name__,module.__version__)
</code></pre></div>
class_names = [‘T-shirt’,’Trouser’,’Pullover’,’Dress’,<div class="code-wrapper"><pre><code class="hljs">           &#39;Coat&#39;, &#39;Sandal&#39;, &#39;Shirt&#39;, &#39;Sneaker&#39;,
           &#39;Bag&#39;, &#39;Ankle boot&#39;
           ]
</code></pre></div>
fashion_mnist = keras.datasets.fashion_mnist<br>(x_train_all,y_train_all),(x_test,y_test) = fashion_mnist.load_data()<br>x_valid, x_train = x_train_all[:5000], x_train_all[5000:]<br>y_valid, y_train = y_train_all[:5000], y_train_all[5000:]<br>def showDataShape():<div class="code-wrapper"><pre><code class="hljs">print(x_valid.shape, y_valid.shape)
print(x_train.shape, y_train.shape)
print(x_test.shape, y_test.shape)
</code></pre></div>
def show_single_image(img_arr):<div class="code-wrapper"><pre><code class="hljs"> plt.imshow(img_arr,cmap=&quot;binary&quot;)
 plt.show()
</code></pre></div>
def show_images(n_rows, n_cols, x_data, y_data, class_names):<div class="code-wrapper"><pre><code class="hljs">assert len(x_data) == len(y_data)
assert n_rows * n_cols &lt; len(x_data)
plt.figure(figsize = (n_cols * 1.4, n_rows * 1.6))
for row in range(n_rows):
    for col in range(n_cols):
        index = n_cols * row + col
        plt.subplot(n_rows, n_cols, index+1)
        plt.imshow(x_data[index], cmap=&quot;binary&quot;,interpolation=&quot;nearest&quot;)
        plt.axis(&quot;off&quot;)
        plt.title(class_names[y_data[index]])
plt.show()
</code></pre></div>
def nn():<div class="code-wrapper"><pre><code class="hljs">model = keras.models.Sequential()   #  keras.Sequential() 好像与此一样
model.add(keras.layers.Flatten(input_shape=[28,28]))
model.add(keras.layers.Dense(300,activation=&quot;relu&quot;))
model.add(keras.layers.Dense(100,activation=&quot;relu&quot;))  # relu : y = max(0,x)
model.add(keras.layers.Dense(10,activation=&quot;softmax&quot;))
&quot;&quot;&quot;
或
model = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[28,28]),
    keras.layers.Dense(300,activation=&quot;relu&quot;),
    keras.layers.Dense(100,activation=&quot;relu&quot;),
    keras.layers.Dense(10,activation=&quot;softmax&quot;)
])
&quot;&quot;&quot;
# softmax : x = [x1, x2, x3],
#   y = [e^x1/sum, e^x2/sum,e^x3/sum]   sum = e^x1+e^x2+e^x3
model.compile(loss=&quot;sparse_categorical_crossentropy&quot;,
              optimizer = &quot;adam&quot;,  # 若loss太低,可能是算法的问题,换用优化过的梯度下降算法
              metrics = [&#39;accuracy&#39;])
# model.summary()  # 显示模型信息
history = model.fit(x_train,y_train,epochs=10,validation_data=(x_valid,y_valid))
# history.history  # 中间结果 json
return history
</code></pre></div>
def plot_learning_curves(history):<div class="code-wrapper"><pre><code class="hljs">pd.DataFrame(history.history).plot(figsize=(8,5))
plt.grid(True)
plt.gca().set_ylim(0,1)
plt.show()
</code></pre></div>
if <strong>name</strong> ==”<strong>main</strong>“:<div class="code-wrapper"><pre><code class="hljs">pass
# show_single_image(x_train[0])
# showVersion()
# show_images(3,5,x_train,y_train,class_names)
history = nn()
plot_learning_curves(history)
</code></pre></div>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><code class="hljs css"><br>   <br><br><span class="hljs-number">2</span>. ```python<br>   # coding:utf-<span class="hljs-number">8</span><br>   # file: tf_keras_classification_model_normalizer.py<br>   # author: Dean<br>   # contact: <span class="hljs-number">1028968939</span>@qq.com<br>   # time: <span class="hljs-number">2019</span>/<span class="hljs-number">12</span>/<span class="hljs-number">17</span> <span class="hljs-number">11</span>:<span class="hljs-number">47</span><br>   # desc: 归一化提高准确率<br>   <br>   import matplotlib as mpl<br>   import matplotlib.pyplot as plt<br>   import numpy as np<br>   import sklearn<br>   import pandas as pd<br>   import os,sys,time<br>   import tensorflow as tf<br>   from tensorflow import keras<br>   def <span class="hljs-built_in">showVersion</span>():<br>       <span class="hljs-built_in">print</span>((tf.__version__))<br>       <span class="hljs-built_in">print</span>(sys.version_info)<br>       for module in mpl, np, pd, sklearn, tf, keras:<br>           <span class="hljs-built_in">print</span>(module.__name__,module.__version__)<br>   <br>   class_names = [<span class="hljs-string">&#x27;T-shirt&#x27;</span>,<span class="hljs-string">&#x27;Trouser&#x27;</span>,<span class="hljs-string">&#x27;Pullover&#x27;</span>,<span class="hljs-string">&#x27;Dress&#x27;</span>,<br>                  <span class="hljs-string">&#x27;Coat&#x27;</span>, <span class="hljs-string">&#x27;Sandal&#x27;</span>, <span class="hljs-string">&#x27;Shirt&#x27;</span>, <span class="hljs-string">&#x27;Sneaker&#x27;</span>,<br>                  <span class="hljs-string">&#x27;Bag&#x27;</span>, <span class="hljs-string">&#x27;Ankle boot&#x27;</span><br>                  ]<br>   <br>   fashion_mnist = keras.datasets.fashion_mnist<br>   (x_train_all,y_train_all),(x_test,y_test) = fashion_mnist.<span class="hljs-built_in">load_data</span>()<br>   x_valid, x_train = x_train_all[:<span class="hljs-number">5000</span>], x_train_all[<span class="hljs-number">5000</span>:]<br>   y_valid, y_train = y_train_all[:<span class="hljs-number">5000</span>], y_train_all[<span class="hljs-number">5000</span>:]<br>   # 归一化处理 x = (x-u) / std   x-减去均值/方差  : 均值是<span class="hljs-number">0</span>方差是<span class="hljs-number">1</span>的正态分布<br>   from sklearn.preprocessing import StandardScaler<br>   scaler = <span class="hljs-built_in">StandardScaler</span>()<br>   # x_train:[None,<span class="hljs-number">28</span>,<span class="hljs-number">28</span>] ----&gt;[None, <span class="hljs-number">784</span>] ------&gt;[None, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>]<br>   x_train_scaled = scaler.<span class="hljs-built_in">fit_transform</span>(x_train.<span class="hljs-built_in">astype</span>(np.float32).<span class="hljs-built_in">reshape</span>(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)).<span class="hljs-built_in">reshape</span>(-<span class="hljs-number">1</span>,<span class="hljs-number">28</span>,<span class="hljs-number">28</span>)<br>   x_valid_scaled = scaler.<span class="hljs-built_in">transform</span>(x_valid.<span class="hljs-built_in">astype</span>(np.float32).<span class="hljs-built_in">reshape</span>(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)).<span class="hljs-built_in">reshape</span>(-<span class="hljs-number">1</span>,<span class="hljs-number">28</span>,<span class="hljs-number">28</span>)  # 使用训练集的均值,方差<br>   x_test_scaled = scaler.<span class="hljs-built_in">transform</span>(x_test.<span class="hljs-built_in">astype</span>(np.float32).<span class="hljs-built_in">reshape</span>(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)).<span class="hljs-built_in">reshape</span>(-<span class="hljs-number">1</span>,<span class="hljs-number">28</span>,<span class="hljs-number">28</span>)<br>   <br>   def <span class="hljs-built_in">nn</span>():<br>       model = keras.models.<span class="hljs-built_in">Sequential</span>()   #  keras.<span class="hljs-built_in">Sequential</span>() 好像与此一样<br>       model.<span class="hljs-built_in">add</span>(keras.layers.<span class="hljs-built_in">Flatten</span>(input_shape=[<span class="hljs-number">28</span>,<span class="hljs-number">28</span>]))<br>       model.<span class="hljs-built_in">add</span>(keras.layers.<span class="hljs-built_in">Dense</span>(<span class="hljs-number">300</span>,activation=<span class="hljs-string">&quot;relu&quot;</span>))<br>       model.<span class="hljs-built_in">add</span>(keras.layers.<span class="hljs-built_in">Dense</span>(<span class="hljs-number">100</span>,activation=<span class="hljs-string">&quot;relu&quot;</span>))  # relu : y = <span class="hljs-built_in">max</span>(<span class="hljs-number">0</span>,x)<br>       model.<span class="hljs-built_in">add</span>(keras.layers.<span class="hljs-built_in">Dense</span>(<span class="hljs-number">10</span>,activation=<span class="hljs-string">&quot;softmax&quot;</span>))<br>   <br>       model.<span class="hljs-built_in">compile</span>(loss=<span class="hljs-string">&quot;sparse_categorical_crossentropy&quot;</span>,<br>                     optimizer = <span class="hljs-string">&quot;adam&quot;</span>,  # 若loss太低,可能是算法的问题,换用优化过的梯度下降算法<br>                     metrics = [<span class="hljs-string">&#x27;accuracy&#x27;</span>])<br>       history = model.<span class="hljs-built_in">fit</span>(x_train_scaled,y_train,epochs=<span class="hljs-number">10</span>,validation_data=(x_valid_scaled,y_valid))<br>       model.<span class="hljs-built_in">evaluate</span>(x_test_scaled,y_test)  # 验证集验证<br>       return history<br>   <br>   def <span class="hljs-built_in">plot_learning_curves</span>(history):<br>       pd.<span class="hljs-built_in">DataFrame</span>(history.history).<span class="hljs-built_in">plot</span>(figsize=(<span class="hljs-number">8</span>,<span class="hljs-number">5</span>))<br>       plt.<span class="hljs-built_in">grid</span>(True)<br>       plt.<span class="hljs-built_in">gca</span>().<span class="hljs-built_in">set_ylim</span>(<span class="hljs-number">0</span>,<span class="hljs-number">1</span>)<br>       plt.<span class="hljs-built_in">show</span>()<br>   if __name__ ==<span class="hljs-string">&quot;__main__&quot;</span>:<br>       pass<br>       history = <span class="hljs-built_in">nn</span>()<br>       <span class="hljs-built_in">plot_learning_curves</span>(history)<br></code></pre></td></tr></table></figure></li>
</ol>
</li>
<li><h3 id="回调函数"><a href="#回调函数" class="headerlink" title="回调函数"></a>回调函数</h3><ol>
<li><p>module: tf.keras.callbacks(本文中只有重要的几个)</p>
<ul>
<li><p>EarlyStopping:提起终止训练</p>
</li>
<li><p>ModelCheckpoint:每隔一段时间保存模型</p>
</li>
<li><p>TensorBoard:可在训练过程中图形化显示</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># coding:utf-8</span><br><span class="hljs-comment"># file: tf_keras_classification_model_callbacks.py</span><br><span class="hljs-comment"># author: Dean</span><br><span class="hljs-comment"># contact: 1028968939@qq.com</span><br><span class="hljs-comment"># time: 2019/12/17 11:47</span><br><span class="hljs-comment"># desc: 回调函数</span><br><br><span class="hljs-keyword">import</span> matplotlib <span class="hljs-keyword">as</span> mpl<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> sklearn<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> os,sys,time<br><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">from</span> tensorflow <span class="hljs-keyword">import</span> keras<br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">showVersion</span>():</span><br>    <span class="hljs-built_in">print</span>((tf.__version__))<br>    <span class="hljs-built_in">print</span>(sys.version_info)<br>    <span class="hljs-keyword">for</span> module <span class="hljs-keyword">in</span> mpl, np, pd, sklearn, tf, keras:<br>        <span class="hljs-built_in">print</span>(module.__name__,module.__version__)<br><br>class_names = [<span class="hljs-string">&#x27;T-shirt&#x27;</span>,<span class="hljs-string">&#x27;Trouser&#x27;</span>,<span class="hljs-string">&#x27;Pullover&#x27;</span>,<span class="hljs-string">&#x27;Dress&#x27;</span>,<br>               <span class="hljs-string">&#x27;Coat&#x27;</span>, <span class="hljs-string">&#x27;Sandal&#x27;</span>, <span class="hljs-string">&#x27;Shirt&#x27;</span>, <span class="hljs-string">&#x27;Sneaker&#x27;</span>,<br>               <span class="hljs-string">&#x27;Bag&#x27;</span>, <span class="hljs-string">&#x27;Ankle boot&#x27;</span><br>               ]<br><br>fashion_mnist = keras.datasets.fashion_mnist<br>(x_train_all,y_train_all),(x_test,y_test) = fashion_mnist.load_data()<br>x_valid, x_train = x_train_all[:<span class="hljs-number">5000</span>], x_train_all[<span class="hljs-number">5000</span>:]<br>y_valid, y_train = y_train_all[:<span class="hljs-number">5000</span>], y_train_all[<span class="hljs-number">5000</span>:]<br><br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler<br>scaler = StandardScaler()<br><br>x_train_scaled = scaler.fit_transform(x_train.astype(np.float32).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">28</span>,<span class="hljs-number">28</span>)<br>x_valid_scaled = scaler.transform(x_valid.astype(np.float32).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">28</span>,<span class="hljs-number">28</span>)  <span class="hljs-comment"># 使用训练集的均值,方差</span><br>x_test_scaled = scaler.transform(x_test.astype(np.float32).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">28</span>,<span class="hljs-number">28</span>)<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">nn</span>():</span><br>    model = keras.models.Sequential()   <span class="hljs-comment">#  keras.Sequential() 好像与此一样</span><br>    model.add(keras.layers.Flatten(input_shape=[<span class="hljs-number">28</span>,<span class="hljs-number">28</span>]))<br>    model.add(keras.layers.Dense(<span class="hljs-number">300</span>,activation=<span class="hljs-string">&quot;relu&quot;</span>))<br>    model.add(keras.layers.Dense(<span class="hljs-number">100</span>,activation=<span class="hljs-string">&quot;relu&quot;</span>))  <span class="hljs-comment"># relu : y = max(0,x)</span><br>    model.add(keras.layers.Dense(<span class="hljs-number">10</span>,activation=<span class="hljs-string">&quot;softmax&quot;</span>))<br><br>    model.<span class="hljs-built_in">compile</span>(loss=<span class="hljs-string">&quot;sparse_categorical_crossentropy&quot;</span>,<br>                  optimizer = <span class="hljs-string">&quot;adam&quot;</span>,  <span class="hljs-comment"># 若loss太低,可能是算法的问题,换用优化过的梯度下降算法</span><br>                  metrics = [<span class="hljs-string">&#x27;accuracy&#x27;</span>])<br><br>    <span class="hljs-comment"># Tensorboard,EarlyStopping,ModelCheckpoint</span><br>    <span class="hljs-comment"># 相对路径可能会报错，另外注意tf2.0以上版本，使用tensorboard时命令行路径不能有中文，最好是进入事件文件所在文件夹 --logdir=. 报错可能小，一般报错都是因为中文路径问题，还有就是--logdir的问题，相对，绝对路径问题(好像是这样，出错时多试试即可，宗旨，少使用中文，logdir=.)</span><br>    logdir = <span class="hljs-string">r&quot;D:\desktop\Workspace\PythonWorkSpace\Tensorflow2.0\Tensorflow2.0_谷歌\callbacks&quot;</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(logdir):<br>        os.mkdir(logdir)<br>    output_model_file = os.path.join(logdir,<span class="hljs-string">&quot;fashion_mnist_model.h5&quot;</span>)<br>    callbacks = [<br>        keras.callbacks.TensorBoard(logdir),<br>        keras.callbacks.ModelCheckpoint(output_model_file,save_best_only = <span class="hljs-literal">True</span>),  <span class="hljs-comment"># 默认保存最近一次训练,True表示保存效果最好的</span><br>        keras.callbacks.EarlyStopping(patience = <span class="hljs-number">5</span>, min_delta = <span class="hljs-number">1e-3</span>)  <span class="hljs-comment"># 提前结束 当阈值低于1e-3时记录一次,5次后停止</span><br>    ]<br>    history = model.fit(x_train_scaled,y_train,epochs=<span class="hljs-number">10</span>,<br>                        validation_data=(x_valid_scaled,y_valid),<br>                        callbacks = callbacks)<br>    model.evaluate(x_test_scaled,y_test)  <span class="hljs-comment"># 验证集验证</span><br>    <span class="hljs-keyword">return</span> history<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_learning_curves</span>(<span class="hljs-params">history</span>):</span><br>    pd.DataFrame(history.history).plot(figsize=(<span class="hljs-number">8</span>,<span class="hljs-number">5</span>))<br>    plt.grid(<span class="hljs-literal">True</span>)<br>    plt.gca().set_ylim(<span class="hljs-number">0</span>,<span class="hljs-number">1</span>)<br>    plt.show()<br><span class="hljs-keyword">if</span> __name__ ==<span class="hljs-string">&quot;__main__&quot;</span>:<br>    history = nn()<br>    plot_learning_curves(history)<br></code></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
</li>
</ol>
</li>
<li><h3 id="图像分类-房价预测"><a href="#图像分类-房价预测" class="headerlink" title="图像分类,房价预测"></a>图像分类,房价预测</h3></li>
<li><h3 id="知识点总结"><a href="#知识点总结" class="headerlink" title="知识点总结"></a>知识点总结</h3><ol>
<li><p>分类问题,回归问题,损失函数</p>
</li>
<li><p>神经网络,激活函数,批量归一化,Dropout</p>
<ol>
<li><p>Min-max 归一化:  $x*=\frac{x-min}{max-min}$</p>
</li>
<li><p>Z-score归一化:  $x*= \frac{x-\mu}{\sigma}$</p>
</li>
<li><p>批归一化:将输入的归一化扩展到每层激活值上,每层的输出是下一层的输入,都做归一化</p>
</li>
<li><p>归一化可以加速训练,<font color="red">一定程度上缓解梯度消失</font></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># coding:utf-8</span><br><span class="hljs-comment"># file: tf_keras_classification_model_dnn.py</span><br><span class="hljs-comment"># author: Dean</span><br><span class="hljs-comment"># contact: 1028968939@qq.com</span><br><span class="hljs-comment"># time: 2019/12/17 11:47</span><br><span class="hljs-comment"># desc: 深度神经网络</span><br><br><span class="hljs-keyword">import</span> matplotlib <span class="hljs-keyword">as</span> mpl<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> sklearn<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> os,sys,time<br><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">from</span> tensorflow <span class="hljs-keyword">import</span> keras<br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">showVersion</span>():</span><br>    <span class="hljs-built_in">print</span>((tf.__version__))<br>    <span class="hljs-built_in">print</span>(sys.version_info)<br>    <span class="hljs-keyword">for</span> module <span class="hljs-keyword">in</span> mpl, np, pd, sklearn, tf, keras:<br>        <span class="hljs-built_in">print</span>(module.__name__,module.__version__)<br><br>class_names = [<span class="hljs-string">&#x27;T-shirt&#x27;</span>,<span class="hljs-string">&#x27;Trouser&#x27;</span>,<span class="hljs-string">&#x27;Pullover&#x27;</span>,<span class="hljs-string">&#x27;Dress&#x27;</span>,<br>               <span class="hljs-string">&#x27;Coat&#x27;</span>, <span class="hljs-string">&#x27;Sandal&#x27;</span>, <span class="hljs-string">&#x27;Shirt&#x27;</span>, <span class="hljs-string">&#x27;Sneaker&#x27;</span>,<br>               <span class="hljs-string">&#x27;Bag&#x27;</span>, <span class="hljs-string">&#x27;Ankle boot&#x27;</span><br>               ]<br><br>fashion_mnist = keras.datasets.fashion_mnist<br>(x_train_all,y_train_all),(x_test,y_test) = fashion_mnist.load_data()<br>x_valid, x_train = x_train_all[:<span class="hljs-number">5000</span>], x_train_all[<span class="hljs-number">5000</span>:]<br>y_valid, y_train = y_train_all[:<span class="hljs-number">5000</span>], y_train_all[<span class="hljs-number">5000</span>:]<br><br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler<br>scaler = StandardScaler()<br><br>x_train_scaled = scaler.fit_transform(x_train.astype(np.float32).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">28</span>,<span class="hljs-number">28</span>)<br>x_valid_scaled = scaler.transform(x_valid.astype(np.float32).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">28</span>,<span class="hljs-number">28</span>)  <span class="hljs-comment"># 使用训练集的均值,方差</span><br>x_test_scaled = scaler.transform(x_test.astype(np.float32).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)).reshape(-<span class="hljs-number">1</span>,<span class="hljs-number">28</span>,<span class="hljs-number">28</span>)<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">nn</span>():</span><br>    model = keras.models.Sequential()<br>    model.add(keras.layers.Flatten(input_shape=[<span class="hljs-number">28</span>,<span class="hljs-number">28</span>]))<br>    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">20</span>):  <span class="hljs-comment"># 循环生成网络</span><br>        model.add(keras.layers.Dense(<span class="hljs-number">100</span>,activation=<span class="hljs-string">&quot;relu&quot;</span>))  <span class="hljs-comment"># 若使用&quot;selu&quot; 是一个自带归一化的激活函数,使用它不用自己归一化</span><br>        model.add(keras.layers.BatchNormalization())<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        对于先激活还是先归一化,不确定,好像都可以,因此下边写法也对</span><br><span class="hljs-string">        model.add(keras.layers.Dense(100))</span><br><span class="hljs-string">        model.add(keras.layers.BatchNormalization())</span><br><span class="hljs-string">        model.add(keras.layers.Activation(&#x27;relu&#x27;))</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>    model.add(keras.layers.AlphaDropout(rate=<span class="hljs-number">0.5</span>))  <span class="hljs-comment"># dropout层,更强大的dropout,drop后均值,方差不变,归一化性质不变  因此可与selu一起使用</span><br>    <span class="hljs-comment"># model.add(keras.layers.Dropout(rate=0.5))</span><br>    model.add(keras.layers.Dense(<span class="hljs-number">10</span>,activation=<span class="hljs-string">&quot;softmax&quot;</span>))<br><br>    model.<span class="hljs-built_in">compile</span>(loss=<span class="hljs-string">&quot;sparse_categorical_crossentropy&quot;</span>,<br>                  optimizer = <span class="hljs-string">&quot;adam&quot;</span>,<br>                  metrics = [<span class="hljs-string">&#x27;accuracy&#x27;</span>])<br>    logdir = <span class="hljs-string">r&quot;D:\desktop\Workspace\PythonWorkSpace\Tensorflow2.0\Tensorflow2.0_谷歌\dnn-callbacks&quot;</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(logdir):<br>        os.mkdir(logdir)<br>    output_model_file = os.path.join(logdir,<span class="hljs-string">&quot;fashion_mnist_model.h5&quot;</span>)<br>    callbacks = [<br>        keras.callbacks.TensorBoard(logdir),<br>        keras.callbacks.ModelCheckpoint(output_model_file,save_best_only = <span class="hljs-literal">True</span>),<br>        keras.callbacks.EarlyStopping(patience = <span class="hljs-number">5</span>, min_delta = <span class="hljs-number">1e-3</span>)<br>    ]<br>    history = model.fit(x_train_scaled,y_train,epochs=<span class="hljs-number">10</span>,<br>                        validation_data=(x_valid_scaled,y_valid),<br>                        callbacks = callbacks)<br>    model.evaluate(x_test_scaled,y_test)  <span class="hljs-comment"># 验证集验证</span><br>    <span class="hljs-keyword">return</span> history<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_learning_curves</span>(<span class="hljs-params">history</span>):</span><br>    pd.DataFrame(history.history).plot(figsize=(<span class="hljs-number">8</span>,<span class="hljs-number">5</span>))<br>    plt.grid(<span class="hljs-literal">True</span>)<br>    plt.gca().set_ylim(<span class="hljs-number">0</span>,<span class="hljs-number">3</span>)<br>    plt.show()<br><span class="hljs-keyword">if</span> __name__ ==<span class="hljs-string">&quot;__main__&quot;</span>:<br>    history = nn()<br>    plot_learning_curves(history)<br></code></pre></td></tr></table></figure></li>
</ol>
</li>
<li><p>Wide,deep模型 超参数搜索</p>
<ol>
<li><p>稀疏特征</p>
<ol>
<li>离散值特征</li>
<li>One-hot表示,则是稀疏特征</li>
<li>Eg: 词表={‘你好’,’你’,….} 你={0,1,0,0,0,0…}</li>
<li>可以叉乘</li>
<li>优点:有效,应用于工业界</li>
<li>缺点:<ol>
<li>需要人工设计</li>
<li>可能过拟合</li>
</ol>
</li>
</ol>
</li>
<li><p>密集特征</p>
<ol>
<li>向量表达<ol>
<li>Eg: 词表={人工智能,他,你,慕课网}</li>
<li>他=[0.3,0.5,0.3,(维向量)]</li>
</ol>
</li>
<li>Word2vec工具</li>
<li>优点:<ol>
<li>带有语义信息,不同向量之间有相关性</li>
<li>兼容没有出现过的特征组合</li>
<li>更少的人工参与</li>
</ol>
</li>
<li>绝点:过度泛化</li>
</ol>
</li>
<li><p><img src="https://img2018.cnblogs.com/blog/1333782/201912/1333782-20191223173052716-1006708621.png" srcset="/img/loading.gif" lazyload></p>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
<div class="code-wrapper"><pre><code class="hljs">        ![](https://img2018.cnblogs.com/blog/1333782/201912/1333782-20191223173106031-530432268.png)

  
     4. 子类API
  
     5. 功能API(函数式API)
  
     6. 多输入与多输出
  
        <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></div></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># coding:utf-8</span><br><span class="hljs-comment"># file: tf_keras_regression_wide_deep.py</span><br><span class="hljs-comment"># author: Dean</span><br><span class="hljs-comment"># contact: 1028968939@qq.com</span><br><span class="hljs-comment"># time: 2019/12/17 11:47</span><br><span class="hljs-comment"># desc: wide &amp;&amp; deep</span><br><br><span class="hljs-keyword">import</span> matplotlib <span class="hljs-keyword">as</span> mpl<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> sklearn<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> os,sys,time<br><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">from</span> tensorflow <span class="hljs-keyword">import</span> keras<br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">showVersion</span>():</span><br>    <span class="hljs-built_in">print</span>((tf.__version__))<br>    <span class="hljs-built_in">print</span>(sys.version_info)<br>    <span class="hljs-keyword">for</span> module <span class="hljs-keyword">in</span> mpl, np, pd, sklearn, tf, keras:<br>        <span class="hljs-built_in">print</span>(module.__name__,module.__version__)<br><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> fetch_california_housing<br>housing = fetch_california_housing()<br><br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br>(x_train_all,x_test,y_train_all,y_test) = train_test_split(<br>    housing.data,housing.target,random_state=<span class="hljs-number">7</span><br>)<br>x_train, x_valid,y_train, y_valid = train_test_split(<br>    x_train_all,y_train_all,random_state=<span class="hljs-number">11</span><br>)<br><br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler<br>scaler = StandardScaler()<br><br>x_train_scaled = scaler.fit_transform(x_train)<br>x_valid_scaled = scaler.transform(x_valid)<br>x_test_scaled = scaler.transform(x_test)<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">nn</span>():</span><br>    <span class="hljs-keyword">pass</span><br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    # 函数式API</span><br><span class="hljs-string">    input = keras.layers.Input(shape=x_train.shape[1:])</span><br><span class="hljs-string">    hidden1 = keras.layers.Dense(30,activation=&quot;relu&quot;)(input)</span><br><span class="hljs-string">    hidden2 = keras.layers.Dense(30,activation=&quot;relu&quot;)(hidden1)</span><br><span class="hljs-string"></span><br><span class="hljs-string">    concat = keras.layers.concatenate([input,hidden2])  # 拼接   input 直接到输出,input经过hidden后输出   此时input 是相同的</span><br><span class="hljs-string">    output = keras.layers.Dense(1)(concat)</span><br><span class="hljs-string">    model = keras.models.Model(inputs=[input],outputs=[output])</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    # 子类API</span><br><span class="hljs-string">    class WideDeepModel(keras.models.Model):</span><br><span class="hljs-string">        def __init__(self):</span><br><span class="hljs-string">            super(WideDeepModel,self).__init__()</span><br><span class="hljs-string">            # 定义模型的层次</span><br><span class="hljs-string">            self.hidden1_layer = keras.layers.Dense(30,activation=&quot;relu&quot;)</span><br><span class="hljs-string">            self.hidden2_layer = keras.layers.Dense(30,activation=&quot;relu&quot;)</span><br><span class="hljs-string">            self.output_layer = keras.layers.Dense(1)</span><br><span class="hljs-string">        def call(self,input):</span><br><span class="hljs-string">            # 完成模型的正向计算</span><br><span class="hljs-string">            hidden1 = self.hidden1_layer(input)</span><br><span class="hljs-string">            hidden2 = self.hidden2_layer(hidden1)</span><br><span class="hljs-string">            concat = keras.layers.concatenate([input,hidden2])</span><br><span class="hljs-string">            output = self.output_layer(concat)</span><br><span class="hljs-string">            return output</span><br><span class="hljs-string">    model = WideDeepModel()  # model = keras.models.Sequential([WideDeepModel(),])</span><br><span class="hljs-string">    model.build(input_shape=(None,8))</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    # 多输入</span><br><span class="hljs-string">    input_wide = keras.layers.Input(shape=[5])</span><br><span class="hljs-string">    input_deep = keras.layers.Input(shape=[6])</span><br><span class="hljs-string">    hidden1 = keras.layers.Dense(30,activation=&quot;relu&quot;)(input_deep)</span><br><span class="hljs-string">    hidden2 = keras.layers.Dense(30,activation=&quot;relu&quot;)(hidden1)</span><br><span class="hljs-string">    concat = keras.layers.concatenate([input_wide,hidden2])   # 拼接input是不同的</span><br><span class="hljs-string">    output = keras.layers.Dense(1)(concat)</span><br><span class="hljs-string">    model = keras.models.Model(inputs=[input_deep,input_wide],</span><br><span class="hljs-string">                              outputs=[output])</span><br><span class="hljs-string">    x_train_scaled_wide = x_train_scaled[:, :5]</span><br><span class="hljs-string">    x_train_scaled_deep = x_train_scaled[:, 2:]</span><br><span class="hljs-string">    x_valid_scaled_wide = x_valid_scaled[:, :5]</span><br><span class="hljs-string">    x_valid_scaled_deep = x_valid_scaled[:, 2:]</span><br><span class="hljs-string">    x_test_scaled_wide = x_test_scaled[:, :5]</span><br><span class="hljs-string">    x_test_scaled_deep = x_test_scaled[:, 2:]</span><br><span class="hljs-string">    # fit ,evaluate 中换对应数据即可 实现多输入x_train_scaled ---&gt;[x_train_scaled_wide,x_train_scaled_deep] 还要验证输入,测试输入</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 多输出</span><br>    input_wide = keras.layers.Input(shape=[<span class="hljs-number">5</span>])<br>    input_deep = keras.layers.Input(shape=[<span class="hljs-number">6</span>])<br>    hidden1 = keras.layers.Dense(<span class="hljs-number">30</span>, activation=<span class="hljs-string">&quot;relu&quot;</span>)(input_deep)<br>    hidden2 = keras.layers.Dense(<span class="hljs-number">30</span>, activation=<span class="hljs-string">&quot;relu&quot;</span>)(hidden1)<br>    concat = keras.layers.concatenate([input_wide, hidden2])  <span class="hljs-comment"># 拼接input是不同的</span><br>    output = keras.layers.Dense(<span class="hljs-number">1</span>)(concat)   <span class="hljs-comment"># 此时有两个输出</span><br>    output2 = keras.layers.Dense(<span class="hljs-number">1</span>)(hidden2)<br>    model = keras.models.Model(inputs=[input_deep, input_wide],<br>                               outputs=[output,output2])<br>    <span class="hljs-comment"># deep,wide 同上进行分割,注意此时fit时 y_train-----&gt;[y_train,y_train]  还有验证y_valid y_test</span><br>    <span class="hljs-comment"># ===================================================</span><br>    model.summary()<br>    model.<span class="hljs-built_in">compile</span>(loss=<span class="hljs-string">&quot;mean_squared_error&quot;</span>, optimizer=<span class="hljs-string">&quot;adam&quot;</span>)  <span class="hljs-comment"># 若出现梯度爆炸 可换用梯度下降算法</span><br>    callbacks = [keras.callbacks.EarlyStopping(patience=<span class="hljs-number">5</span>, min_delta=<span class="hljs-number">1e-4</span>)]<br><br>    history = model.fit(x_train_scaled,y_train,epochs=<span class="hljs-number">100</span>,<br>                        validation_data=(x_valid_scaled,y_valid),<br>                        callbacks=callbacks)<br>    model.evaluate(x_test_scaled,y_test)  <span class="hljs-comment"># 验证集验证</span><br>    <span class="hljs-keyword">return</span> history<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_learning_curves</span>(<span class="hljs-params">history</span>):</span><br>    pd.DataFrame(history.history).plot(figsize=(<span class="hljs-number">8</span>,<span class="hljs-number">5</span>))<br>    plt.grid(<span class="hljs-literal">True</span>)<br>    plt.gca().set_ylim(<span class="hljs-number">0</span>,<span class="hljs-number">1</span>)<br>    plt.show()<br><span class="hljs-keyword">if</span> __name__ ==<span class="hljs-string">&quot;__main__&quot;</span>:<br>    history = nn()<br>    plot_learning_curves(history)<br></code></pre></td></tr></table></figure>
     7. 超参数搜索
     
        1. 神经网络训练过程不变的参数
           1. 网络结构参数:几层,每层宽度,每层激活函数等
        2. 训练参数:batch_size,学习率,学习衰减算法等
        2. 手工试耗费人力
        3. 搜索策略
           1. 网格搜索
              - 定义n维方格
              - 每个方格对应一组超参数
              - 一组一组尝试
              - 例如,学习率定义m个,dropout n个,交叉m\*n 次运算
           2. 随机搜索
              - 在网格搜索的网格中,随机搜索,次数变多,
           3. 遗传算法搜索
              1. 对自然界模拟
              2. A,初始化参数集合-&gt;训练-&gt;得到模型指标作为生存概率
              3. B,选择-&gt;交叉-&gt;变异-&gt;产生下一代集合
              4. C,重新到A
           4. 启发式搜索
              1. 研究热点-AutoML
              2. 使用循环神经网络生成参数
              3. 使用强化学习来进行反馈,使用模型来训练生成参数
     
        <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># coding:utf-8</span><br><span class="hljs-comment"># file: tf_keras_regression_hp_search.py</span><br><span class="hljs-comment"># author: Dean</span><br><span class="hljs-comment"># contact: 1028968939@qq.com</span><br><span class="hljs-comment"># time: 2019/12/17 11:47</span><br><span class="hljs-comment"># desc: 超参数搜索</span><br>         <br><span class="hljs-keyword">import</span> matplotlib <span class="hljs-keyword">as</span> mpl<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> sklearn<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> os,sys,time<br><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">from</span> tensorflow <span class="hljs-keyword">import</span> keras<br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">showVersion</span>():</span><br>    <span class="hljs-built_in">print</span>((tf.__version__))<br>    <span class="hljs-built_in">print</span>(sys.version_info)<br>    <span class="hljs-keyword">for</span> module <span class="hljs-keyword">in</span> mpl, np, pd, sklearn, tf, keras:<br>        <span class="hljs-built_in">print</span>(module.__name__,module.__version__)<br><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> fetch_california_housing<br>housing = fetch_california_housing()<br>         <br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br>(x_train_all,x_test,y_train_all,y_test) = train_test_split(<br>    housing.data,housing.target,random_state=<span class="hljs-number">7</span><br>)<br>x_train, x_valid,y_train, y_valid = train_test_split(<br>    x_train_all,y_train_all,random_state=<span class="hljs-number">11</span><br>)<br>         <br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler<br>scaler = StandardScaler()<br>         <br>x_train_scaled = scaler.fit_transform(x_train)<br>x_valid_scaled = scaler.transform(x_valid)<br>x_test_scaled = scaler.transform(x_test)<br>         <br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">nn</span>():</span><br>    <span class="hljs-comment"># 超参数搜索</span><br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    # 自实现超参数搜索,本例简单,顺序运行,参数单一</span><br><span class="hljs-string">    # learning_rate:[1e-3,3e-4,1e-4,3e-3,1e-2,3e-2]</span><br><span class="hljs-string">    learning_rate = [1e-3,3e-4,1e-4,3e-3,1e-2,3e-2]</span><br><span class="hljs-string">    # w = w + learning_rate * grad</span><br><span class="hljs-string">    historys =[]</span><br><span class="hljs-string">    for lr in learning_rate:</span><br><span class="hljs-string">        model = keras.models.Sequential([</span><br><span class="hljs-string">            keras.layers.Dense(30,activation=&quot;relu&quot;,input_shape=x_train.shape[1:]),</span><br><span class="hljs-string">            keras.layers.Dense(1)</span><br><span class="hljs-string">        ])</span><br><span class="hljs-string">        optimizer = keras.optimizers.Adam(lr) # lr应该是根据不同的策略会逐渐衰减的</span><br><span class="hljs-string">        model.compile(loss=&quot;mean_squared_error&quot;, optimizer=optimizer)</span><br><span class="hljs-string">        callbacks = [keras.callbacks.EarlyStopping(patience=5, min_delta=1e-2)]</span><br><span class="hljs-string">        history = model.fit(x_train_scaled,y_train,epochs=100,</span><br><span class="hljs-string">                            validation_data=(x_valid_scaled,y_valid),</span><br><span class="hljs-string">                            callbacks=callbacks)</span><br><span class="hljs-string">        historys.append(history)</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># RandomizedSearchCV</span><br>    <span class="hljs-comment"># 1,转化为sklear的model</span><br>    <span class="hljs-comment">#   tf.keras.wrappers.scikit_learn.KerasRegressor</span><br>    <span class="hljs-comment">#   tf.keras.wrappers.scikit_learn.KerasClassifier</span><br>    <span class="hljs-comment"># 2,定义参数集合</span><br>    <span class="hljs-comment"># 3,搜索参数</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">build_model</span>(<span class="hljs-params">hidden_layers = <span class="hljs-number">1</span>,layer_size = <span class="hljs-number">30</span>, learning_rate = <span class="hljs-number">3e-3</span></span>):</span><br>        model = keras.models.Sequential()<br>        model.add(keras.layers.Dense(layer_size,activation=<span class="hljs-string">&quot;relu&quot;</span>,input_shape=x_train.shape[<span class="hljs-number">1</span>:]))<br>        <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(hidden_layers - <span class="hljs-number">1</span>):<br>            model.add(keras.layers.Dense(layer_size,activation=<span class="hljs-string">&quot;relu&quot;</span>))<br>        model.add(keras.layers.Dense(<span class="hljs-number">1</span>))<br>        optimizer = keras.optimizers.Adam(learning_rate)<br>        model.<span class="hljs-built_in">compile</span>(loss=<span class="hljs-string">&quot;mean_squared_error&quot;</span>, optimizer=optimizer)<br>        <span class="hljs-keyword">return</span> model<br>    sklearn_model = keras.wrappers.scikit_learn.KerasRegressor(build_model) <span class="hljs-comment"># 传入函数名</span><br>         <br>    <span class="hljs-keyword">from</span> scipy.stats <span class="hljs-keyword">import</span> reciprocal<br>    <span class="hljs-comment"># f(x) = 1/(x*log(b/a))  a&lt;=x&lt;=b</span><br>    param_distribution = &#123;<br>        <span class="hljs-string">&quot;hidden_layers&quot;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>],<br>        <span class="hljs-string">&quot;layer_size&quot;</span>: np.arange(<span class="hljs-number">1</span>, <span class="hljs-number">100</span>),  <span class="hljs-comment"># [1,2,3....100]</span><br>        <span class="hljs-string">&quot;learning_rate&quot;</span>: reciprocal(<span class="hljs-number">1e-4</span>, <span class="hljs-number">1e-2</span>)  <span class="hljs-comment"># 按照某种分布生成</span><br>    &#125;<br>    <br>    <span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> RandomizedSearchCV<br>    random_search_cv = RandomizedSearchCV(sklearn_model,<br>                                          param_distribution,<br>                                          cv = <span class="hljs-number">5</span>,  <span class="hljs-comment"># 交叉验证 份数</span><br>                                          n_iter=<span class="hljs-number">10</span>,  <span class="hljs-comment"># 随机寻找参数组合的数量，默认值为10。</span><br>                                          n_jobs=<span class="hljs-number">1</span>)  <span class="hljs-comment"># 并行计算时使用的计算机核心数量，默认值为1。当n_jobs的值设为-1时，则使用所有的处理器。</span><br>    callbacks = [keras.callbacks.EarlyStopping(patience=<span class="hljs-number">5</span>, min_delta=<span class="hljs-number">1e-2</span>)]<br>    history = random_search_cv.fit(x_train_scaled, y_train, epochs=<span class="hljs-number">100</span>,   <span class="hljs-comment"># 还使用fit</span><br>                            validation_data=(x_valid_scaled, y_valid),<br>                            callbacks=callbacks)<br>    <span class="hljs-comment"># cross_validation:交叉验证 ,训练集分为n份 n-1份训练,1份测试</span><br>    random_search_cv.best_params_  <span class="hljs-comment"># 最好的参数</span><br>    random_search_cv.best_score_  <span class="hljs-comment"># 最好的参数对应的分数</span><br>    model = random_search_cv.best_estimator_.model  <span class="hljs-comment"># 最好的模型</span><br>    model.evaluate(x_test_scaled,y_test)  <span class="hljs-comment"># 测试</span><br>    <br>    <span class="hljs-keyword">return</span> historys<br>         <br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_learning_curves</span>(<span class="hljs-params">history</span>):</span><br>    pd.DataFrame(history.history).plot(figsize=(<span class="hljs-number">8</span>,<span class="hljs-number">5</span>))<br>    plt.grid(<span class="hljs-literal">True</span>)<br>    plt.gca().set_ylim(<span class="hljs-number">0</span>,<span class="hljs-number">1</span>)<br>    plt.show()<br><span class="hljs-keyword">if</span> __name__ ==<span class="hljs-string">&quot;__main__&quot;</span>:<br>    historys = nn()<br>    <span class="hljs-keyword">for</span> history <span class="hljs-keyword">in</span> historys:<br>        <span class="hljs-built_in">print</span>()<br>        plot_learning_curves(history)<br><br></code></pre></td></tr></table></figure>
</code></pre>
<ol start="3">
<li><h1 id="Tensorflow基础API使用"><a href="#Tensorflow基础API使用" class="headerlink" title="Tensorflow基础API使用"></a>Tensorflow基础API使用</h1><ol>
<li><h3 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h3><ol>
<li>Tf框架:基础数据类型,自定义模型与损失函数,自定义求导,tf.function,图结构\</li>
<li>项目:图像分类,房价预测</li>
</ol>
</li>
<li><h3 id="知识点-1"><a href="#知识点-1" class="headerlink" title="知识点"></a>知识点</h3><ol>
<li>基础API</li>
<li>基础API与keras的集成<ol>
<li>自定义损失函数</li>
<li>自定义层次</li>
</ol>
</li>
<li>@tf.function的使用(2.0专有:将python转化为图结构)</li>
<li>自定义求导</li>
</ol>
</li>
<li><h3 id="tf-function"><a href="#tf-function" class="headerlink" title="@tf.function"></a>@tf.function</h3><ol>
<li>将python函数编译为图</li>
<li>易于将模型导出为GraphDef+checkpoint 或者SavedModel</li>
<li>使得eager execution可以默认打开</li>
<li>1.0的代码可以通过tf.function在2.0继续使用<ol>
<li>代替session</li>
</ol>
</li>
</ol>
</li>
<li><h3 id="API"><a href="#API" class="headerlink" title="API"></a>API</h3><ol>
<li><p>基础数据类型</p>
<ol>
<li><p>Tf.constant,tf.string</p>
<ol>
<li>```python<h1 id="0维-一个数-shape"><a href="#0维-一个数-shape" class="headerlink" title="0维 一个数 shape=()"></a>0维 一个数 shape=()</h1><h1 id="1维-列表-shape-n"><a href="#1维-列表-shape-n" class="headerlink" title="1维 列表 shape=(n)"></a>1维 列表 shape=(n)</h1><h1 id="2维-二维数组-shape-m-n"><a href="#2维-二维数组-shape-m-n" class="headerlink" title="2维 二维数组 shape=(m,n)"></a>2维 二维数组 shape=(m,n)</h1>t = tf.constant([<div class="code-wrapper"><pre><code class="hljs">[1,2,3],
[4,5,6]
</code></pre></div>
])  # 2.0中可以直接获取值<br>print(t)<br>print(t[:,1:])<br>print(t[…,2]) # 一维向量 tf.Tensor([3 6], shape=(2,), dtype=int32)<br>print(t+10)  # 都加上10<br>print(tf.square(t))  # 每个数平方<br>print(t @ tf.transpose(t))  # 返回t与它转置的乘积 2<em>2<br>print(t.numpy())  # 直接转化为numpy对象 2</em>3矩阵<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><br>2. ```python<br>   t = tf.constant(<span class="hljs-string">&quot;tensorflow&quot;</span>)<br>   <span class="hljs-builtin-name">print</span>(t)  # tf.Tensor(b<span class="hljs-string">&#x27;tensorflow&#x27;</span>, shape=(), <span class="hljs-attribute">dtype</span>=string)<br>   <span class="hljs-builtin-name">print</span>(tf.strings.length(t))  # tf.Tensor(10, shape=(), <span class="hljs-attribute">dtype</span>=int32)<br>   <span class="hljs-builtin-name">print</span>(tf.strings.length(t,<span class="hljs-attribute">unit</span>=<span class="hljs-string">&quot;UTF8_CHAR&quot;</span>))  # tf.Tensor(10, shape=(), <span class="hljs-attribute">dtype</span>=int32)<br>   <span class="hljs-builtin-name">print</span>(tf.strings.unicode_decode(t,<span class="hljs-string">&quot;utf8&quot;</span>))  # tf.Tensor([116 101 110 115 111 114 102 108 111 119], shape=(10,), <span class="hljs-attribute">dtype</span>=int32)<br>   t = tf.constant([<span class="hljs-string">&#x27;cafe&#x27;</span>,<span class="hljs-string">&#x27;coffee&#x27;</span>,<span class="hljs-string">&#x27;咖啡&#x27;</span>])  #<br>   <span class="hljs-builtin-name">print</span>(tf.strings.length(t,<span class="hljs-attribute">unit</span>=<span class="hljs-string">&quot;UTF8_CHAR&quot;</span>))  # tf.Tensor([4 6 2], shape=(3,), <span class="hljs-attribute">dtype</span>=int32)<br>   <span class="hljs-builtin-name">print</span>(tf.strings.unicode_decode(t,<span class="hljs-string">&quot;utf8&quot;</span>))  # &lt;tf.RaggedTensor [[99, 97, 102, 101], [99, 111, 102, 102, 101, 101], [21654, 21857]]&amp;gt;<br></code></pre></td></tr></table></figure></li>
</ol>
</li>
<li><p>tf.ragged.constant,tfSpareTensor</p>
<ol>
<li><p>```python<br>v = tf.Variable([[1,2,3,4],[5,6,7,8]])<br>print(v)  # Variable 对象<br>print(v.value())  # tensor<br>print(v.numpy())  # numpy矩阵</p>
<h1 id="重新赋值-不能用等于号"><a href="#重新赋值-不能用等于号" class="headerlink" title="重新赋值,不能用等于号"></a>重新赋值,不能用等于号</h1><p>v.assign(2*v)<br>v[0,1].assign(42)<br>v[1].assign([9,10,11,12])</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs lua"><br><span class="hljs-number">2.</span> ```python<br>   t = tf.ragged.constant(<span class="hljs-string">[[11,12],[13,14,15]]</span>)<br>   <span class="hljs-built_in">print</span>(t)  # &lt;tf.RaggedTensor <span class="hljs-string">[[11, 12], [13, 14, 15]]</span>&amp;gt;<br>   <span class="hljs-built_in">print</span>(t[<span class="hljs-number">1</span>])  # tf.Tensor([<span class="hljs-number">13</span> <span class="hljs-number">14</span> <span class="hljs-number">15</span>], shape=(<span class="hljs-number">3</span>,), dtype=int32)<br>   <span class="hljs-built_in">print</span>(t[<span class="hljs-number">1</span>:<span class="hljs-number">2</span>])  # &lt;tf.RaggedTensor <span class="hljs-string">[[13, 14, 15]]</span>&amp;gt;<br>   <span class="hljs-built_in">print</span>(tf.<span class="hljs-built_in">concat</span>([t,t],axis=<span class="hljs-number">0</span>))  # 按照行拼接变为<span class="hljs-number">4</span>行<br>   <span class="hljs-built_in">print</span>(tf.<span class="hljs-built_in">concat</span>([t,t],axis=<span class="hljs-number">1</span>))  # 若要按照列拼接,首先行数要相同<br>   <span class="hljs-built_in">print</span>(t.to_tensor())  # 变为普通tensor 空的位置补为<span class="hljs-number">0</span>,<span class="hljs-number">0</span>都在正常值后边<br></code></pre></td></tr></table></figure></li>
<li><p>```python<br>t = tf.SparseTensor(indices=[[0,1],[1,0],[2,3]],  # 注意必须先[0,1] 再[0,2] 否则to_dense 会报错,若必须不按顺序 tf.sparse.reorder(t) 即可使用</p>
<div class="code-wrapper"><pre><code class="hljs">                values=[1,2,3],
                dense_shape=[3,4])
</code></pre></div>
<p>print(t)  # 存储稀疏矩阵,指定值位置,数值,shape即可<br>print(tf.sparse.to_dense(t))  # 转换为普通tensor</p>
<h1 id="不能加法"><a href="#不能加法" class="headerlink" title="不能加法"></a>不能加法</h1><p>t2 = tf.constant(“..”)  # 普通的4<em>3 Tensor<br>tf.sparse.sparse_dense_matmul(t,t2)  # 得到的是3</em>3普通Tensor</p>
<figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs reasonml"><br><span class="hljs-number">2.</span> 自定义损失函数------<span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">Tf</span>.</span></span>reduce_mean<br><br>   ```python<br>    def customized<span class="hljs-constructor">_mse(<span class="hljs-params">y_true</span>, <span class="hljs-params">y_pred</span>)</span>:<br>           return tf.reduce<span class="hljs-constructor">_mean(<span class="hljs-params">tf</span>.<span class="hljs-params">square</span>(<span class="hljs-params">y_pred</span> - <span class="hljs-params">y_true</span>)</span>)<br>    model.compile(loss=customized_mse, optimizer=<span class="hljs-string">&quot;adam&quot;</span>,metrics=<span class="hljs-literal">[&quot;<span class="hljs-identifier">mean_squared_error</span>&quot;]</span>)<br></code></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
</li>
<li><p>自定义层次—–Keras.layers.Lambda和继承法</p>
<ol>
<li>```python<br>layer = tf.keras.layers.Dense(100,input_shape=[None,5])<br>layer(tf.zero([10,5]))   # 输出[10,100] 二维<h1 id="10-5-w-b-10-100"><a href="#10-5-w-b-10-100" class="headerlink" title="[10,5] * w  +b = [10,100]"></a>[10,5] * w  +b = [10,100]</h1><h1 id="w-5-100"><a href="#w-5-100" class="headerlink" title="w  [5:100]"></a>w  [5:100]</h1>layer.trainable_variables # 获得kernel 与bias 可以查看<h1 id="———————————————"><a href="#———————————————" class="headerlink" title="———————————————"></a>———————————————</h1> class CustomizedDenseLayer(keras.layers.Layer):<div class="code-wrapper"><pre><code class="hljs">    def __init__(self,units,activation=None,**kwargs):
        self.units = units
        self.activation = keras.layers.Activation(activation)
        super(CustomizedDenseLayer, self).__init__(**kwargs)
    def build(self,input_shape):
        &quot;&quot;&quot;构建需要的参数&quot;&quot;&quot;
        # x * w +b [None,a] w[a,b] [None,b]
        self.kernel = self.add_weight(name=&quot;kernel&quot;,
                                      shape=(input_shape[1],self.units),
                                      initilizer=&quot;uniform&quot;, # 定义随机初始化kernel的方法:此处使用均匀分布
                                      trainable=True)
        self.bias = self.add_weight(name=&quot;bias&quot;,
                                    shape=(self.units,),
                                    initilizer=&quot;zeros&quot;,
                                    trainable=True)
        super(CustomizedDenseLayer,self).build(input_shape)
    def call(self,x):
        &quot;&quot;&quot;完整的正向计算&quot;&quot;&quot;
        return self.activation(x @ self.kernel + self.bias)  # @ 表示矩阵乘法

model = keras.models.Sequential([
    CustomizedDenseLayer(30, activation=&quot;relu&quot;, input_shape=x_train.shape[1:]),
    CustomizedDenseLayer(1)
])
</code></pre></div>
<figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs reasonml"><br><span class="hljs-number">2.</span> ```python<br>    # 定义简单的层次,激活函数层,dropout层等<br>       #   eg:tf.nn.softplus: log(<span class="hljs-number">1</span>+e^x)<br>       # customized_softplus = keras.layers.<span class="hljs-constructor">Dense(1,<span class="hljs-params">activation</span>=<span class="hljs-string">&quot;softplus&quot;</span>)</span> = keras.layers.<span class="hljs-constructor">Dense(1)</span>,keras.layers.<span class="hljs-constructor">Activation(<span class="hljs-string">&quot;softplus&quot;</span>)</span><br>       customized_softplus = keras.layers.<span class="hljs-constructor">Lambda(<span class="hljs-params">lambda</span> <span class="hljs-params">x</span>:<span class="hljs-params">tf</span>.<span class="hljs-params">nn</span>.<span class="hljs-params">softplus</span>(<span class="hljs-params">x</span>)</span>)<br></code></pre></td></tr></table></figure></li>
</ol>
</li>
<li><p>Tf.function</p>
<ol>
<li><p>Tf.fucntion,tf.autograph.to_code, </p>
<ol>
<li><p>```python</p>
<h1 id="python-—–-gt-图"><a href="#python-—–-gt-图" class="headerlink" title="python —–&gt;图"></a>python —–&gt;图</h1><h1 id="法一"><a href="#法一" class="headerlink" title="法一"></a>法一</h1><p>def scaled_elu(z,scale=1.0,alpha=1.0):   # python函数</p>
<div class="code-wrapper"><pre><code class="hljs"># z&gt;=0?scale *z :scale * alpha * tf.nn.elu(z)
is_positive = tf.greater_equal(z,0.0)
return scale * tf.where(is_positive,z,alpha * tf.nn.elu(z))
</code></pre></div>
<p>print(scaled_elu(tf.constant(-3)))   #   常量<br>print(scaled_elu(tf.constant([-3,-2.5])))  # 列表向量  都何以全部接受并处理<br>scaled_elu_tf = tf.function(scaled_elu)<br>scaled_elu_tf.python_function  # 返回原来的python函数<br>print(scaled_elu(tf.constant(-3)))<br>print(scaled_elu(tf.constant([-3,-2.5]))) # 与上边结果相同,转换的作用是速度加快</p>
<h1 id="法二"><a href="#法二" class="headerlink" title="法二"></a>法二</h1><h1 id="1-1-2-…-1-2-n"><a href="#1-1-2-…-1-2-n" class="headerlink" title="1+1/2+….1/2^n"></a>1+1/2+….1/2^n</h1><p>@tf.function<br>def converge_to(n_iters):</p>
<div class="code-wrapper"><pre><code class="hljs">total = tf.constant(0.)
increment = tf.constant(1.)
for _ in range(n_iters):
    total += increment
    increment /= 2.0
return total
</code></pre></div>
<p>print(converge_to(20))</p>
<figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs reasonml"><br><span class="hljs-number">2.</span> ```python<br>   def display<span class="hljs-constructor">_tf_code(<span class="hljs-params">func</span>)</span>:<br>       # 中间代码<br>       # python代码转为tf代码, 图就是通过此转换的<br>       code = tf.autograph.<span class="hljs-keyword">to</span><span class="hljs-constructor">_code(<span class="hljs-params">func</span>)</span>   # 还有to_graph 是将代码转为图的<br>       from <span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">IPython</span>.</span></span>display import display,Markdown<br>       display(<span class="hljs-constructor">Markdown(&#x27;```<span class="hljs-params">python</span>\<span class="hljs-params">n</span>&#123;&#125;\<span class="hljs-params">n</span>```&#x27;.<span class="hljs-params">format</span>(<span class="hljs-params">code</span>)</span>))<br>   display<span class="hljs-constructor">_tf_code(<span class="hljs-params">scaled_elu</span>)</span><br></code></pre></td></tr></table></figure></li>
<li><p>```python<br>var = tf.Variable(0.)<br>@tf.function<br>def add_21():</p>
<div class="code-wrapper"><pre><code class="hljs">return var.assign_add(21)
</code></pre></div>
<p>print(add_21())  # 结果返回21的tensor   ,若var在内部会报错, 神经网络中大多是变量,需要在外边初始化</p>
<p>@tf.function(input_signature=[tf.TensorSpec([None],tf.int32,name=’x’)])<br>def cube(z):  # 可接收浮点数,整数  使用输入签名后会限制只能输入int32</p>
<div class="code-wrapper"><pre><code class="hljs">return tf.pow(z,3)
</code></pre></div>
<p>print(cube(tf.constant([1.2,2.6])))<br>print(cube(tf.constant([1,2])))</p>
<figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs reasonml"><br><span class="hljs-number">4.</span> ```python<br>   # 只有经过输入签名的才能保存为Saved_Model,在这个过程中使用get_concrete_function,把tf.<span class="hljs-keyword">function</span>标注的转换为有图建议的函数<br>   cube_func_int32 = cube.get<span class="hljs-constructor">_concrete_function(<span class="hljs-params">tf</span>.TensorSpec([None],<span class="hljs-params">tf</span>.<span class="hljs-params">int32</span>)</span>)<br>   <br>   print(cube_func_int32 is cube.get<span class="hljs-constructor">_concerte_function(<span class="hljs-params">tf</span>.TensorSpec([2],<span class="hljs-params">tf</span>.<span class="hljs-params">int32</span>)</span>))<br></code></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
</li>
<li><p>GraphDef</p>
<ol>
<li><p>get_operations,get_operation_by_name</p>
</li>
<li><p>get_tensorf_by_name,as_graph_def</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">cube_func_int32.graph  <span class="hljs-comment"># 图</span><br>cube_func_int32.graph.get_operations()  <span class="hljs-comment"># 获取操作</span><br>cube_func_int32.graph.get_operations()[<span class="hljs-number">2</span>]  <span class="hljs-comment"># 获取某一个操作</span><br>cube_func_int32.graph.get_operations()[<span class="hljs-number">2</span>].xxx  <span class="hljs-comment"># 获取某一个操作中的某个属性</span><br><br>cube_func_int32.graph.get_operation_by_name(<span class="hljs-string">&quot;operationName&quot;</span>)  <span class="hljs-comment"># 通过operation名字获取</span><br>cube_func_int32.graph.get_tensor_by_name(<span class="hljs-string">&quot;x:0&quot;</span>)  <span class="hljs-comment"># 通过tensor名字获取</span><br><br>cube_func_int32.graph.as_graph_def()  <span class="hljs-comment"># 显示图的结构信息</span><br><br><span class="hljs-comment"># 主要用来保存图结构,模型,恢复图结构,模型</span><br></code></pre></td></tr></table></figure></li>
</ol>
</li>
<li><p>自动求导</p>
<ol>
<li><p>普通求导方法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">f</span>(<span class="hljs-params">x</span>):</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">3.</span> * x ** <span class="hljs-number">2</span> + <span class="hljs-number">2.</span> * x -<span class="hljs-number">1</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">approximae_derivative</span>(<span class="hljs-params">f,x,eps= <span class="hljs-number">1e-3</span></span>):</span>  <span class="hljs-comment"># 求函数 f 在 x 点的导数</span><br>    <span class="hljs-comment"># x点向右eps, 向左eps 中间直线的斜率近似导数, eps足够小,导数足够接近</span><br>    <span class="hljs-keyword">return</span> (f(x+eps)-f(x-eps))/(<span class="hljs-number">2</span>*eps)<br><span class="hljs-comment"># print(approximae_derivative(f,1))</span><br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">g</span>(<span class="hljs-params">x1,x2</span>):</span><br>    <span class="hljs-keyword">return</span> (x1 + <span class="hljs-number">5</span>)*(x2 ** <span class="hljs-number">2</span>)<br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">approximae_gredient</span>(<span class="hljs-params">g,x1,x2,eps=<span class="hljs-number">1e-3</span></span>):</span><br>    dg_x1 = approximae_derivative(<span class="hljs-keyword">lambda</span> x:g(x,x2),x1,eps)<br>    dg_x2 = approximae_derivative(<span class="hljs-keyword">lambda</span> x:g(x1,x),x2,eps)<br>    <span class="hljs-keyword">return</span> dg_x1,dg_x2<br><span class="hljs-comment"># print(approximae_gredient(g,2,3))</span><br></code></pre></td></tr></table></figure></li>
<li><p>Tf.GrandientTape</p>
<ol>
<li><p>```python<br>x1 = tf.Variable(2.0)<br>x2 = tf.Variable(3.0)<br>with tf.GradientTape(persistent = True) as tape:</p>
<div class="code-wrapper"><pre><code class="hljs">z = g(x1,x2)
</code></pre></div>
<p>dz_x1 = tape.gradient(z,x1)  # 9.0<br>dz_x2 = tape.gradient(z,x2)   # tape 只能使用一次,本次会报错 GradientTape(persistent=Ture) 表示不释放tape就可以多次使用,但使用完毕后需要手动释放那个资源<br>print(dz_x1,dz_x2)<br>del tape</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs nix"><br>   <br><br><span class="hljs-number">2</span>. ```python<br>   <span class="hljs-keyword">with</span> tf.GradientTape(<span class="hljs-attr">persistent</span> = True) as tape: <span class="hljs-comment"># 不用persistent</span><br>       <span class="hljs-attr">z</span> = g(x1,x2)<br>   dz_x1,<span class="hljs-attr">dz_x2</span> = tape.gradient(z,[x1,x2])   <span class="hljs-comment"># 也可以这样一次求出两个</span><br></code></pre></td></tr></table></figure></li>
<li><p>```python</p>
<h1 id="当x1-x2-为tf-constant-时-返回值为None"><a href="#当x1-x2-为tf-constant-时-返回值为None" class="headerlink" title="当x1,x2 为tf.constant()时,返回值为None"></a>当x1,x2 为tf.constant()时,返回值为None</h1><p>with tf.GradientTape(persistent = True) as tape:  # 这样修改即可</p>
<div class="code-wrapper"><pre><code class="hljs">tape.watch(x1)
tape.watch(x2)
z = g(x1,x2)
</code></pre></div>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs apache"><br>   <br><br><span class="hljs-attribute">4</span>. ```python<br>   <span class="hljs-attribute">x</span> = tf.Variable(<span class="hljs-number">5</span>.<span class="hljs-number">0</span>)<br>   <span class="hljs-attribute">with</span> tf.GradientTape() as tape:<br>       <span class="hljs-attribute">z1</span> = <span class="hljs-number">3</span> * x<br>       <span class="hljs-attribute">z2</span> = x **<span class="hljs-number">2</span><br>   <span class="hljs-attribute">tape</span>.gradient([z<span class="hljs-number">1</span>,z<span class="hljs-number">2</span>],x)  # z<span class="hljs-number">1</span>对于x的导数加上z<span class="hljs-number">2</span>对于x的导数<br></code></pre></td></tr></table></figure></li>
<li><p>```python</p>
<h1 id="二阶导数"><a href="#二阶导数" class="headerlink" title="二阶导数"></a>二阶导数</h1><p>x1 = tf.Variable(2.0)<br>x2 = tf.Variable(3.0)<br>with tf.GradientTape(persistent=True) as outer_tape:</p>
<div class="code-wrapper"><pre><code class="hljs">with tf.GradientTape(persistent=True) as inner_tape:
    z = g(x1,x2)
inner_grads = inner_tape.gradient(z,[x1,x2])
</code></pre></div>
<p>outer_grads = [outer_tape.gradient(inner_grad,[x1,x2])</p>
<div class="code-wrapper"><pre><code class="hljs">           for inner_grad in inner_grads]
</code></pre></div>
<p>print(outer_grads)<br>del inner_tape<br>del outer_tape</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs apache"><br>   <br><br><span class="hljs-attribute">6</span>. ```python<br>   <span class="hljs-comment"># 简单梯度下降</span><br>   <span class="hljs-attribute">learning_rate</span> = <span class="hljs-number">0</span>.<span class="hljs-number">1</span><br>   <span class="hljs-attribute">x</span> = tf.Variable(<span class="hljs-number">0</span>.<span class="hljs-number">0</span>)<br>   <span class="hljs-attribute">for</span> _ in range(<span class="hljs-number">100</span>):<br>       <span class="hljs-attribute">with</span> tf.GradientTape() as tape:<br>           <span class="hljs-attribute">z</span> = <span class="hljs-number">3</span>. * x ** <span class="hljs-number">2</span> + <span class="hljs-number">2</span>. * x -<span class="hljs-number">1</span><br>       <span class="hljs-attribute">dz_dx</span> = tape.gradient(z,x)<br>       <span class="hljs-attribute">x</span>.assign_sub(learning_rate*dz_dx)<br>   <span class="hljs-attribute">print</span>(x) # -<span class="hljs-number">0</span>.<span class="hljs-number">333333</span><br></code></pre></td></tr></table></figure></li>
</ol>
</li>
<li><p>Optimizer.apply_gradients</p>
<ol>
<li><p>```python</p>
<h1 id="优化梯度下降"><a href="#优化梯度下降" class="headerlink" title="优化梯度下降"></a>优化梯度下降</h1><p>learning_rate = 0.1<br>x = tf.Variable(0.0)<br>optimizer = keras.optimizers.SGD(lr = learning_rate)<br>for _ in range(100):</p>
<div class="code-wrapper"><pre><code class="hljs">with tf.GradientTape() as tape:
    z = 3. * x ** 2 + 2. * x -1
dz_dx = tape.gradient(z,x)
optimizer.apply_gradients([(dz_dx,x)])  # 与上边不同
</code></pre></div>
<p>print(x) # -0.333333</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash"><br>2. ```python<br>   def <span class="hljs-built_in">test</span>():<br>       metric = keras.metrics.MeanSquaredError()  <span class="hljs-comment"># 第一个形参是真实值,第二个是预测值  返回的是平均 均方误差</span><br>       <span class="hljs-built_in">print</span>(metric([5],[2]))  <span class="hljs-comment"># 9</span><br>       <span class="hljs-built_in">print</span>(metric([0],[1]))  <span class="hljs-comment"># 5</span><br>       <span class="hljs-built_in">print</span>(metric.result())  <span class="hljs-comment"># 5</span><br>       metric.reset_statues()  <span class="hljs-comment"># 不再累加</span><br>       <span class="hljs-built_in">print</span>(metric([1],[3]))  <span class="hljs-comment"># 4</span><br></code></pre></td></tr></table></figure></li>
<li><p>```python<br>def nn(): </p>
<div class="code-wrapper"><pre><code class="hljs"># fit 的内容
#   1,batch 遍历训练集 metric
#       1.1,自动求导
#   2,epoch结束 验证集 metric
epochs = 100
batch_size = 32
steps_per_epoch = len(x_train_scaled) // batch_size
optimizer = keras.optimizers.SGD()
metric = keras.metrics.MeanSquaredError()

def random_batch(x,y,batch_size=32):
    idx = np.random.randint(0,len(x),size=batch_size)  # 在0到 len(x) 中随机取batch_size个数
    return x[idx],y[idx]
model = keras.models.Sequential([
    keras.layers.Dense(30,activation=&quot;relu&quot;,input_shape=x_train.shape[1:]),
    keras.layers.Dense(1),
])
for epoch in range(epochs):
    metric.reset_states()
    for step in range(steps_per_epoch):
        x_batch,y_batch = random_batch(x_train_scaled,y_train,batch_size)  # 获取数据
        with tf.GradientTape() as  tape:
            y_pred = model(x_batch)  # 计算预测
            loss = tf.reduce_mean(keras.losses.mean_squared_error(y_batch,y_pred))  # 定义损失函数
            metric(y_batch,y_pred)
        grads = tape.gradient(loss,model.variables)
        grads_and_vars = zip(grads,model.variables)   # 每个参数对应他的梯度
        optimizer.apply_gradients(grads_and_vars)  # 将梯度的变化应用到变量上
        print(&quot;\rEpoch&quot;,epoch,&quot;train mse:&quot;,metric.result().numpy(),end=&quot;&quot;)
    y_valid_pred = model(x_valid_scaled)
    valid_loss = tf.reduce_mean(
        keras.losses.mean_squared_error(y_valid_pred,y_valid)
    )
    print(&quot;\t&quot;,&quot;valid mse&quot;,valid_loss.numpy())
</code></pre></div>
<figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">            <br>               <br><br><span class="hljs-number">4.</span> # Tensorflow dataset使用<br><br>   <span class="hljs-number">1.</span> ### 基础知识<br><br>      <span class="hljs-number">1.</span> Tf框架:<br><br>         <span class="hljs-number">1.</span> 基础api<br><br>            <span class="hljs-number">1.</span> tf.data.<span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">Dateset</span>.</span></span>from_tensor_slics<br><br>               ```python<br>               dataset = tf.data.<span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">Dataset</span>.</span></span>from<span class="hljs-constructor">_tensor_slices((<span class="hljs-params">np</span>.<span class="hljs-params">arange</span>(10)</span>))<br>               print(dataset)  # &lt;TensorSliceDataset shapes: <span class="hljs-literal">()</span>, types: tf.<span class="hljs-built_in">int32</span>&gt;    # 里边的元素每一个为一组<br></code></pre></td></tr></table></figure></li>
<li><p>repeat,batch,interleave,map,shuffle,list_files</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> dataset.batch(<span class="hljs-number">2</span>):  <span class="hljs-comment"># 还是10打个数,但此时每组2个,5组</span><br>     <span class="hljs-built_in">print</span>(item)<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">dataset = dataset.repeat(<span class="hljs-number">3</span>)  <span class="hljs-comment"># dataset 变为30个数,30组</span><br>dataset =dataset.batch(<span class="hljs-number">7</span>)   <span class="hljs-comment"># 每组7个数 5组</span><br><span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> dataset:<br>    <span class="hljs-built_in">print</span>(item)<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># interleave: 将dataset中的每一个数据处理后,合并返回</span><br><span class="hljs-comment"># case:dataset 中是一系列文件的名字,通过他,遍历名字读取内容,使用它合并</span><br>dataset2 = dataset.interleave(<br>    <span class="hljs-keyword">lambda</span> v:tf.data.Dataset.from_tensor_slices(v),  <span class="hljs-comment"># map_fn:处理函数</span><br>    cycle_length=<span class="hljs-number">5</span>, <span class="hljs-comment"># cycle_length:并行处理个数</span><br>    block_length=<span class="hljs-number">5</span> <span class="hljs-comment"># block_length: 从处理的元素中每次取多少个出来 [0,1,2,3,4,5,6]  只取[0,1,2,3,4]  最后不够的时候 从第一个中未取到的取</span><br>)<br><span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> dataset2:<br>    <span class="hljs-built_in">print</span>(item)<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">x = np.array([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>],[<span class="hljs-number">3</span>,<span class="hljs-number">4</span>],[<span class="hljs-number">5</span>,<span class="hljs-number">6</span>]])<br>y = np.array([<span class="hljs-string">&#x27;cat&#x27;</span>,<span class="hljs-string">&#x27;dog&#x27;</span>,<span class="hljs-string">&#x27;fox&#x27;</span>])<br><br>dataset3 = tf.data.Dataset.from_tensor_slices((x,y))<br><span class="hljs-keyword">for</span> item_x,item_y <span class="hljs-keyword">in</span> dataset3:<br>    <span class="hljs-built_in">print</span>(item_x.numpy(),item_y.numpy())<br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">[1 2] b&#x27;cat&#x27;</span><br><span class="hljs-string">[3 4] b&#x27;dog&#x27;</span><br><span class="hljs-string">[5 6] b&#x27;fox&#x27;</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br>dataset4 = tf.data.Dataset.from_tensor_slices(&#123;<span class="hljs-string">&#x27;feature&#x27;</span>:x,<span class="hljs-string">&quot;label&quot;</span>:y&#125;)<br><span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> dataset4:<br>    <span class="hljs-built_in">print</span>(item[<span class="hljs-string">&#x27;feature&#x27;</span>].numpy(),item[<span class="hljs-string">&#x27;label&#x27;</span>].numpy())  <span class="hljs-comment"># 同上</span><br></code></pre></td></tr></table></figure></li>
</ol>
</li>
<li><p>csv文件,</p>
<ol>
<li><p>生成csv</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib <span class="hljs-keyword">as</span> mpl<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> sklearn<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> os,sys,time<br><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">from</span> tensorflow <span class="hljs-keyword">import</span> keras<br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">showVersion</span>():</span><br>    <span class="hljs-built_in">print</span>((tf.__version__))<br>    <span class="hljs-built_in">print</span>(sys.version_info)<br>    <span class="hljs-keyword">for</span> module <span class="hljs-keyword">in</span> mpl, np, pd, sklearn, tf, keras:<br>        <span class="hljs-built_in">print</span>(module.__name__,module.__version__)<br><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> fetch_california_housing<br>housing = fetch_california_housing()<br><br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br>(x_train_all,x_test,y_train_all,y_test) = train_test_split(<br>    housing.data,housing.target,random_state=<span class="hljs-number">7</span><br>)<br>x_train, x_valid,y_train, y_valid = train_test_split(<br>    x_train_all,y_train_all,random_state=<span class="hljs-number">11</span><br>)<br><br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler<br>scaler = StandardScaler()<br><br>x_train_scaled = scaler.fit_transform(x_train)<br>x_valid_scaled = scaler.transform(x_valid)<br>x_test_scaled = scaler.transform(x_test)<br>output_dir = <span class="hljs-string">r&quot;generate_csv&quot;</span><br><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(output_dir):<br>    os.mkdir(output_dir)<br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">save_to_csv</span>(<span class="hljs-params">output_dir,data,name_prefix,header=<span class="hljs-literal">None</span>,n_parts=<span class="hljs-number">10</span></span>):</span><br>    path_format = os.path.join(output_dir,<span class="hljs-string">&quot;&#123;&#125;_&#123;:02d&#125;.csv&quot;</span>)  <span class="hljs-comment"># 文件名格式:第一个表示是train还是test 第二个表示为2位的整数</span><br>    filenames= []<br>    <span class="hljs-keyword">for</span> file_idx,row_indics <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(  <span class="hljs-comment"># 将数据分为索引加数据 通过idx indics获取</span><br>            np.array_split( <span class="hljs-comment"># 将索引分为n_parts部分  [array(1,2,3,4,), array(5,6,7,8..)]</span><br>                np.arange(<span class="hljs-built_in">len</span>(data)),  <span class="hljs-comment"># 生成和data一样长的数组,当索引</span><br>                         n_parts)   <span class="hljs-comment"># 将索引分为n_patrs</span><br>            ):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        file_idx row_indics</span><br><span class="hljs-string">        0       [0,1,2,3,4..]</span><br><span class="hljs-string">        1       [5,6,7,8,9..]</span><br><span class="hljs-string">        2       ...</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-built_in">print</span>(name_prefix,file_idx)<br>        part_csv = path_format.<span class="hljs-built_in">format</span>(name_prefix,file_idx)<br>        filenames.append(part_csv)<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(part_csv,<span class="hljs-string">&quot;wt&quot;</span>,encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:<br>            <span class="hljs-keyword">if</span> header <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                f.write(header+<span class="hljs-string">&quot;\n&quot;</span>)  <span class="hljs-comment"># 写入header</span><br>            <span class="hljs-keyword">for</span> row_index <span class="hljs-keyword">in</span> row_indics:<br>                f.write(<span class="hljs-string">&quot;,&quot;</span>.join([<span class="hljs-built_in">repr</span>(col) <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> data[row_index]]))<br>                f.write(<span class="hljs-string">&#x27;\n&#x27;</span>)<br>    <span class="hljs-keyword">return</span> filenames<br>train_data = np.c_[x_train_scaled,y_train]  <span class="hljs-comment"># 将数据和标签合并</span><br>valid_data = np.c_[x_valid_scaled,y_valid]<br>test_data = np.c_[x_test_scaled,y_test]<br>header_cols = housing.feature_names + [<span class="hljs-string">&#x27;MidianHouseValue&#x27;</span>]<br>header_str = <span class="hljs-string">&#x27;,&#x27;</span>.join(header_cols)<br>train_filenames = save_to_csv(output_dir,train_data,<span class="hljs-string">&quot;train&quot;</span>,header_str,n_parts=<span class="hljs-number">10</span>)<br></code></pre></td></tr></table></figure></li>
<li><p>tf.data.TextLineDataset</p>
</li>
<li><p>tf.io.decode_csv</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 1. filename ---&gt; dataset</span><br><span class="hljs-comment"># 2. read file --&gt; dataset -&gt; datasets -&gt;merge</span><br><span class="hljs-comment"># 3, parse csv</span><br>filename_dataset = tf.data.Dataset.list_files(train_filenames)<br>n_readers =<span class="hljs-number">5</span><br>dataset = filename_dataset.interleave(<br>    <span class="hljs-keyword">lambda</span> filename:tf.data.TextLineDataset(filename).skip(<span class="hljs-number">1</span>),  <span class="hljs-comment"># 根据文件名按照行读取文件内容, 并跳过header</span><br>    cycle_length=n_readers<br>)<br><span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> dataset.take(<span class="hljs-number">15</span>):  <span class="hljs-comment"># 读取数据的前15行</span><br>    <span class="hljs-built_in">print</span>(line.numpy())  <span class="hljs-comment">#  是一个整字符串</span><br><span class="hljs-comment"># tf.io.decode_csv(str,record_defaults)</span><br>sample_str = <span class="hljs-string">&#x27;1,2,3,4,5&#x27;</span><br>records_defaults = [tf.constant(<span class="hljs-number">0</span>,dtype=tf.int32)]*<span class="hljs-number">5</span> <span class="hljs-comment"># 要解析的类型</span><br>records_defaults = [tf.constant(<span class="hljs-number">0</span>,dtype=tf.int32),<span class="hljs-number">0</span>,np.nan,<span class="hljs-string">&quot;hello&quot;</span>,tf.constant([])] <span class="hljs-comment"># 要解析的类型</span><br>parsed_fields = tf.io_csv(sample_str,records_defaults)<br><span class="hljs-built_in">print</span>(parsed_fields)<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse_csv_line</span>(<span class="hljs-params">line,n_fileds=<span class="hljs-number">9</span></span>):</span><br>    defs = [tf.constant(np.nan)] * n_fileds<br>    parsed_fields = tf.io.decode_csv(line,record_defaults=defs)<br>    x = tf.stack(parsed_fields[<span class="hljs-number">0</span>:-<span class="hljs-number">1</span>])<br>    y = tf.stack(parsed_fields[-<span class="hljs-number">1</span>:])<br>    <span class="hljs-keyword">return</span> x,y<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">csv_reader_dataset</span>(<span class="hljs-params">filenames,n_readers=<span class="hljs-number">5</span>,</span></span><br><span class="hljs-params"><span class="hljs-function">                       batch_size=<span class="hljs-number">32</span>,n_parse_threads=<span class="hljs-number">5</span>,  <span class="hljs-comment"># 解析时并行数</span></span></span><br><span class="hljs-params"><span class="hljs-function">                       shuffle_buffer_size=<span class="hljs-number">10000</span></span>):</span>  <span class="hljs-comment"># buffer大小</span><br>    dataset = tf.data.Dataset.list_files(filenames)<br>    dataset = dataset.repeat()  <span class="hljs-comment"># 重复无限次</span><br>    dataset = dataset.interleave(<br>        <span class="hljs-keyword">lambda</span> filename: tf.data.TextLineDataset(filename).skip(<span class="hljs-number">1</span>),<br>        cycle_length= n_readers,<br>    )<br>    dataset.shuffle(shuffle_buffer_size)  <span class="hljs-comment"># 混排</span><br>    dataset = dataset.<span class="hljs-built_in">map</span>(parse_csv_line,num_parallel_calls=n_parse_threads)  <span class="hljs-comment"># 将数据经过处理后返回 与interleave类似</span><br>    dataset = dataset.batch(batch_size)<br>    <span class="hljs-keyword">return</span> dataset<br>train_set = csv_reader_dataset(train_filenames,batch_size=<span class="hljs-number">32</span>)<br>valid_set = csv_reader_dataset(train_filenames,batch_size=<span class="hljs-number">32</span>)  <span class="hljs-comment"># 换位valid_filenames</span><br>model = keras.models.Sequential([<br>        keras.layers.Dense(<span class="hljs-number">30</span>, activation=<span class="hljs-string">&quot;relu&quot;</span>, input_shape=x_train.shape[<span class="hljs-number">8</span>]),<br>        keras.layers.Dense(<span class="hljs-number">1</span>)<br>    ])<br>model.<span class="hljs-built_in">compile</span>(loss=<span class="hljs-string">&#x27;mse&#x27;</span>, optimizer=<span class="hljs-string">&quot;adam&quot;</span>)<br>callbacks = [keras.callbacks.EarlyStopping(patience=<span class="hljs-number">5</span>, min_delta=<span class="hljs-number">1e-4</span>)]<br>history = model.fit(train_set, epochs=<span class="hljs-number">100</span>,<br>                    steps_per_epoch = <span class="hljs-number">1160</span>//<span class="hljs-number">32</span>,  <span class="hljs-comment"># 指定每个epoch 的次数</span><br>                    validation_steps =<span class="hljs-number">3870</span>//<span class="hljs-number">32</span>,<br>                    validation_data=valid_set,<br>                    callbacks=callbacks)<br><span class="hljs-comment"># model.evaluate(test_set,steps = 5160//32)</span><br></code></pre></td></tr></table></figure></li>
</ol>
</li>
<li><p>tfrecord文件</p>
<ol>
<li><p>tf.train.FloatList,    tf.train.Int64List,    tf.train.bytesList</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># tfrecord 文件格式</span><br><span class="hljs-comment"># -&gt; tf.train.Example</span><br><span class="hljs-comment">#   -&gt; tf.train.Features -&gt;&#123;&#x27;key&#x27;:tf.train.Feature&#125;</span><br></code></pre></td></tr></table></figure>
<h1 id="gt-tf-train-Feature-gt-tf-train-ByteList-FloatList-Int64List"><a href="#gt-tf-train-Feature-gt-tf-train-ByteList-FloatList-Int64List" class="headerlink" title="-&gt;tf.train.Feature -&gt;{tf.train.ByteList/FloatList/Int64List}"></a>-&gt;tf.train.Feature -&gt;{tf.train.ByteList/FloatList/Int64List}</h1><p>favorite_books = [name.encode(“utf-8”) for name in [“machine learning”,”cc150”]]<br>favorite_books_bytelist = tf.train.BytesList(value = favorite_books)<br>“””<br>value: “machine learning”<br>value: “cc150”<br>“””<br>hours_floatlist = tf.train.FloatList(value=[15.5,9.0,7.0,8.0])<br>age = tf.train.Int64List(value=[64])</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs vim"><br>   <br><br><span class="hljs-number">2</span>. <span class="hljs-keyword">tf</span>.train.Feature,    <span class="hljs-keyword">tf</span>.train.Features,    <span class="hljs-keyword">tf</span>.train.Example<br><br>   ```<span class="hljs-keyword">python</span><br>   features = <span class="hljs-keyword">tf</span>.train.Features(<br>       feature = &#123;<br>           <span class="hljs-string">&quot;favorite_books&quot;</span>:<span class="hljs-keyword">tf</span>.train.Feature(bytes_list = favorite_books_bytelist),<br>           <span class="hljs-string">&quot;hours&quot;</span>:<span class="hljs-keyword">tf</span>.train.Feature(float_list = hours_floatlist),<br>           <span class="hljs-string">&quot;age&quot;</span>:<span class="hljs-keyword">tf</span>.train.Feature(int64_list = age)<br>       &#125;<br>   )<br>   <span class="hljs-keyword">print</span>(features)  # json格式,显示每个feature<br>   <span class="hljs-string">&quot;&quot;</span><span class="hljs-comment">&quot;</span><br>   feature &#123;<br>     key: <span class="hljs-string">&quot;age&quot;</span><br>     value &#123;<br>       int64_list &#123;<br>         value: <span class="hljs-number">64</span><br>       &#125;<br>     &#125;<br>   &#125;<br>   faeture&#123;....&#125;<br>   <span class="hljs-string">&quot;&quot;</span><span class="hljs-comment">&quot;</span><br>   example = <span class="hljs-keyword">tf</span>.train.Example(features=features)  # 与features 类似   featrues&#123;feature&#123;&#125;...&#125;<br></code></pre></td></tr></table></figure></li>
<li><p>exapmle.SerializeToString</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">serizlized_example = example.SerializeToString()  <span class="hljs-comment"># 压缩,</span><br></code></pre></td></tr></table></figure></li>
<li><p>tf.io.ParseSingleExample</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">output_dir = <span class="hljs-string">&quot;tf_tfrecord_basic&quot;</span><br><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(output_dir):<br>    os.mkdir(output_dir)<br>filename = <span class="hljs-string">&quot;test.tfrecords&quot;</span><br>filename_fullpath = os.path.join(output_dir,filename)<br><span class="hljs-comment"># 写入文件</span><br><span class="hljs-keyword">with</span> tf.io.TFRecordWriter(filename_fullpath) <span class="hljs-keyword">as</span> writer:  <span class="hljs-comment"># 打开文件</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>):  <span class="hljs-comment"># 写进去3次</span><br>        writer.write(serizlized_example)<br><span class="hljs-comment"># 读取</span><br>dataset = tf.data.TFRecordDataset([filename_fullpath])<br><span class="hljs-keyword">for</span> seralized_example <span class="hljs-keyword">in</span> dataset:<br>    <span class="hljs-built_in">print</span>(serizlized_example)   <span class="hljs-comment"># 与上边的serialized_example 类似  压缩过的</span><br><br></code></pre></td></tr></table></figure></li>
<li><p>tf.io.VarLenFeature,tf.io.FixedLenFeature</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">expected_features = &#123;<br>    <span class="hljs-string">&quot;favorite_books&quot;</span>: tf.io.VarLenFeature(dtype=tf.string),   <span class="hljs-comment"># 变长  一会解析后是sparsetensor</span><br>    <span class="hljs-string">&quot;hours&quot;</span>:tf.io.VarLenFeature(dtype=tf.float32),  <span class="hljs-comment"># 变长</span><br>    <span class="hljs-string">&quot;age&quot;</span>:tf.io.FixedLenFeature([],dtype=tf.int64),  <span class="hljs-comment"># 定长,普通的tensor,[] 表示是0维的数,[8] 就表示8特特征</span><br>&#125;<br></code></pre></td></tr></table></figure></li>
<li><p>tf.data.TFRecordDataset,tf.io.TFRecordOptions</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python">dataset = tf.data.TFRecordDataset([filename_fullpath])<br><span class="hljs-keyword">for</span> serialized_example_tensor <span class="hljs-keyword">in</span> dataset:<br>    example = tf.io.parse_single_example(<br>        serialized_example_tensor,<br>        expected_features<br>    )<br>    books = tf.sparse.to_dense(example[<span class="hljs-string">&quot;favorite_books&quot;</span>],default_value=<span class="hljs-string">b&quot;&quot;</span>)  <span class="hljs-comment"># 解析sparsetensor 为tensor  sparsetensor为0的地方 不能转为字符串 要制定default_value</span><br><br>    <span class="hljs-built_in">print</span>(example)<br><br><span class="hljs-comment">#  存为压缩格式</span><br>filename_fullpath_zip = filename_fullpath+ <span class="hljs-string">&quot;.zip&quot;</span><br>options = tf.io.TFRecordOptions(compress_type = <span class="hljs-string">&quot;GZIP&quot;</span>)<br><span class="hljs-keyword">with</span> tf.io.TFRecordWriter(filename_fullpath_zip,options) <span class="hljs-keyword">as</span> writer:<br>    <span class="hljs-keyword">pass</span><br><br><span class="hljs-comment"># 读取压缩格式</span><br>dataset = tf.data.TFRecordDataset([filename_fullpath_zip],compression_type=<span class="hljs-string">&quot;GZIP&quot;</span>)  <span class="hljs-comment"># 其余不变即可</span><br><br></code></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
</li>
<li><p>房价csv转record</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># coding:utf-8</span><br><span class="hljs-comment"># file: tf_data_generate_tfrecord.py</span><br><span class="hljs-comment"># author: Dean</span><br><span class="hljs-comment"># contact: 1028968939@qq.com</span><br><span class="hljs-comment"># time: 2019/12/22 11:29</span><br><span class="hljs-comment"># desc:</span><br><span class="hljs-comment"># coding:utf-8</span><br><span class="hljs-comment"># file: tf_keras_classification_model_dnn.py</span><br><span class="hljs-comment"># author: Dean</span><br><span class="hljs-comment"># contact: 1028968939@qq.com</span><br><span class="hljs-comment"># time: 2019/12/17 11:47</span><br><span class="hljs-comment"># desc: csv 文件转换为record</span><br><br><span class="hljs-keyword">import</span> matplotlib <span class="hljs-keyword">as</span> mpl<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> sklearn<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> os,sys,time<br><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">from</span> tensorflow <span class="hljs-keyword">import</span> keras<br>source_dir = <span class="hljs-string">&quot;generate_csv&quot;</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_filenames_by_prefix</span>(<span class="hljs-params">source_dir,prefix_name</span>):</span>  <span class="hljs-comment"># 按照文件名分类</span><br>    all_files = os.listdir(source_dir)<br>    results=[]<br>    <span class="hljs-keyword">for</span> filename <span class="hljs-keyword">in</span> all_files:<br>        <span class="hljs-keyword">if</span> filename.startswith(prefix_name):<br>            results.append(os.path.join(source_dir,filename))<br>    <span class="hljs-keyword">return</span> results<br>train_filenames = get_filenames_by_prefix(source_dir,<span class="hljs-string">&quot;train&quot;</span>)<br><span class="hljs-keyword">import</span> pprint<br><span class="hljs-comment"># pprint.pprint(train_filenames)  # 换行打印</span><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse_csv_line</span>(<span class="hljs-params">line,n_fileds=<span class="hljs-number">9</span></span>):</span><br>    defs = [tf.constant(np.nan)] * n_fileds<br>    parsed_fields = tf.io.decode_csv(line,record_defaults=defs)<br>    x = tf.stack(parsed_fields[<span class="hljs-number">0</span>:-<span class="hljs-number">1</span>])<br>    y = tf.stack(parsed_fields[-<span class="hljs-number">1</span>:])<br>    <span class="hljs-keyword">return</span> x,y<br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">csv_reader_dataset</span>(<span class="hljs-params">filenames,n_readers=<span class="hljs-number">5</span>,</span></span><br><span class="hljs-params"><span class="hljs-function">                       batch_size=<span class="hljs-number">32</span>,n_parse_threads=<span class="hljs-number">5</span>,  <span class="hljs-comment"># 解析时并行数</span></span></span><br><span class="hljs-params"><span class="hljs-function">                       shuffle_buffer_size=<span class="hljs-number">10000</span></span>):</span>  <span class="hljs-comment"># buffer大小</span><br>    dataset = tf.data.Dataset.list_files(filenames)<br>    dataset = dataset.repeat()  <span class="hljs-comment"># 重复无限次</span><br>    dataset = dataset.interleave(<br>        <span class="hljs-keyword">lambda</span> filename: tf.data.TextLineDataset(filename).skip(<span class="hljs-number">1</span>),<br>        cycle_length= n_readers,<br>    )<br>    dataset.shuffle(shuffle_buffer_size)  <span class="hljs-comment"># 混排</span><br>    dataset = dataset.<span class="hljs-built_in">map</span>(parse_csv_line,num_parallel_calls=n_parse_threads)  <span class="hljs-comment"># 将数据经过处理后返回 与interleave类似</span><br>    dataset = dataset.batch(batch_size)<br>    <span class="hljs-keyword">return</span> dataset<br>train_set = csv_reader_dataset(train_filenames,batch_size=<span class="hljs-number">32</span>)<br><br><span class="hljs-comment"># 遍历数据写入文件</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">serialize_example</span>(<span class="hljs-params">x,y</span>):</span><br>    <span class="hljs-string">&quot;&quot;&quot;Converts x ,y to tf.train.FloatList and serialize&quot;&quot;&quot;</span><br>    input_features = tf.train.FloatList(value=x)<br>    label = tf.train.FloatList(value=y)<br>    features = tf.train.Features(<br>        feature=&#123;<br>            <span class="hljs-string">&quot;input_features&quot;</span>:tf.train.Feature(float_list = input_features),<br>            <span class="hljs-string">&quot;label&quot;</span>:tf.train.Feature(float_list = label)<br>        &#125;<br>    )<br>    example = tf.train.Example(features = features)<br>    <span class="hljs-keyword">return</span> example.SerializeToString()<br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">csv_dataset_to_tfrecords</span>(<span class="hljs-params">base_filename,dataset,n_shards,steps_per_shard,compression_type = <span class="hljs-literal">None</span></span>):</span><br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    n_shard:文件个数</span><br><span class="hljs-string">    steps_per_shard:每个小文件,走多少步</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    options = tf.io.TFRecordOptions(compression_type=compression_type)<br>    all_filenames=[]<br>    <span class="hljs-keyword">for</span> shard_id <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_shards):<br>        filename_fullpath = <span class="hljs-string">&#x27;&#123;&#125;_&#123;:05d&#125;-of-&#123;:05d&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(<br>            base_filename,shard_id,n_shards<br>        )<br>        <span class="hljs-keyword">with</span> tf.io.TFRecordWriter(filename_fullpath,options) <span class="hljs-keyword">as</span> writer:<br>            <span class="hljs-keyword">for</span> x_batch,y_batch <span class="hljs-keyword">in</span> dataset.take(steps_per_shard):  <span class="hljs-comment">#  每个batch都是32个的</span><br>                <span class="hljs-keyword">for</span> x_example,y_example <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(x_batch,y_batch):<br>                    writer.write(serialize_example(x_example,y_example))<br>        all_filenames.append(filename_fullpath)<br>    <span class="hljs-keyword">return</span> all_filenames<br>n_shards = <span class="hljs-number">20</span><br>train_step_per_shard = <span class="hljs-number">11610</span>//<span class="hljs-number">32</span>//n_shards<br>output_dir = <span class="hljs-string">&quot;generate_tfreocrds&quot;</span>  <span class="hljs-comment"># 先创建</span><br>train_basename = os.path.join(output_dir,<span class="hljs-string">&quot;train&quot;</span>)<br><br>train_tfrecord_filename = csv_dataset_to_tfrecords(<br>    train_basename,train_set,n_shards,train_step_per_shard,<span class="hljs-literal">None</span><br>)<br><br><br><span class="hljs-comment"># 读取文件</span><br>expected_feature = &#123;<br>    <span class="hljs-string">&quot;input_ferature&quot;</span>:tf.io.FixedLenFeature([<span class="hljs-number">8</span>],dtype=tf.float32),<br>    <span class="hljs-string">&quot;label&quot;</span>:tf.io.FixedLenFeature([<span class="hljs-number">1</span>],dtype=tf.float32)<br>&#125;<br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse_example</span>(<span class="hljs-params">serialized_example</span>):</span><br>    example = tf.io.parse_single_example(serialize_example,expected_feature)<br>    <span class="hljs-keyword">return</span> expected_feature[<span class="hljs-string">&quot;input_ferature&quot;</span>],expected_feature[<span class="hljs-string">&#x27;label&#x27;</span>]<br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">tfrecord_reader_dataset</span>(<span class="hljs-params">filenames,n_readers=<span class="hljs-number">5</span>,</span></span><br><span class="hljs-params"><span class="hljs-function">                       batch_size=<span class="hljs-number">32</span>,n_parse_threads=<span class="hljs-number">5</span>,  <span class="hljs-comment"># 解析时并行数</span></span></span><br><span class="hljs-params"><span class="hljs-function">                       shuffle_buffer_size=<span class="hljs-number">10000</span></span>):</span>  <span class="hljs-comment"># buffer大小</span><br>    dataset = tf.data.Dataset.list_files(filenames)<br>    dataset = dataset.repeat()  <span class="hljs-comment"># 重复无限次</span><br>    dataset = dataset.interleave(<br>        <span class="hljs-keyword">lambda</span> filename: tf.data.TFRecordDataset(filename,compression_type=nONE),<br>        cycle_length= n_readers,<br>    )<br>    dataset.shuffle(shuffle_buffer_size)  <span class="hljs-comment"># 混排</span><br>    dataset = dataset.<span class="hljs-built_in">map</span>(parse_example,num_parallel_calls=n_parse_threads)  <span class="hljs-comment"># 将数据经过处理后返回 与interleave类似</span><br>    dataset = dataset.batch(batch_size)<br>    <span class="hljs-keyword">return</span> dataset<br>tfrecords_train = tfrecord_reader_dataset(train_tfrecord_filename,<br>                                          batch_size=<span class="hljs-number">3</span>)<br><span class="hljs-keyword">for</span>  x_batch,y_batch <span class="hljs-keyword">in</span> tfrecords_train:<br>    <span class="hljs-built_in">print</span>(x_batch,y_batch)<br></code></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
</li>
<li><h1 id="Tensorflow-Estimator使用与tf1-0"><a href="#Tensorflow-Estimator使用与tf1-0" class="headerlink" title="Tensorflow Estimator使用与tf1.0"></a>Tensorflow Estimator使用与tf1.0</h1><ol>
<li><h3 id="知识点-2"><a href="#知识点-2" class="headerlink" title="知识点"></a>知识点</h3><p>Tf框架:estimator使用,特征列使用,tf1.0基本使用</p>
<p>项目:泰坦尼克号生存</p>
</li>
<li><h3 id="API-1"><a href="#API-1" class="headerlink" title="API"></a>API</h3><ol>
<li><p>Tf.keras.estimator.to_estimator</p>
<ol>
<li><p>Train,evaluate</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># dataset 泰坦尼克号</span><br><span class="hljs-comment"># https://storage.googleapis.com/tf-datasets/titanic/train.csv</span><br><span class="hljs-comment"># https://storage.googleapis.com/tf-datasets/titanic/eval.csv</span><br><br>train_file = <span class="hljs-string">&quot;csv/train.csv&quot;</span><br>eval_file = <span class="hljs-string">&quot;csv/eval.csv&quot;</span><br><br>train_df = pd.read_csv(train_file)  <span class="hljs-comment"># (627,9)</span><br>eval_df = pd.read_csv(eval_file)  <span class="hljs-comment"># (264.9)</span><br><br>y_train = train_df.pop(<span class="hljs-string">&quot;survived&quot;</span>)<br>y_eval = eval_df.pop(<span class="hljs-string">&quot;survived&quot;</span>)<br><span class="hljs-comment"># print(train_df)</span><br><span class="hljs-comment"># print(y_train.head())</span><br><span class="hljs-comment"># print(train_df.describe()) 非离散值的信息</span><br><span class="hljs-comment"># train_df.age.hist(bins = 20)   画出age的分布直方图 bin表示分为多少份</span><br><span class="hljs-comment"># train_df.sex.value_counts().plot(kind=&quot;barh&quot;)  # 横向柱状图 &quot;barv&quot;纵向: 统计男性个数,女性个数</span><br><span class="hljs-comment"># train_df[&#x27;class&#x27;].value_counts().plot(kind=&quot;barh&quot;) 不同舱位人数</span><br><span class="hljs-comment"># 男性,女性中获救比例,</span><br><span class="hljs-comment"># pd.concat([train_df,y_train],axis=1).groupby(&#x27;sex&#x27;).survived.mean()</span><br><br><span class="hljs-comment"># 离散值</span><br>categorical_columns = [<span class="hljs-string">&quot;sex&quot;</span>,<span class="hljs-string">&#x27;n_siblings_spouses&#x27;</span>,<span class="hljs-string">&#x27;parch&#x27;</span>,<span class="hljs-string">&#x27;class&#x27;</span>,<span class="hljs-string">&#x27;deck&#x27;</span>,<span class="hljs-string">&#x27;embark_town&#x27;</span>,<span class="hljs-string">&#x27;alone&#x27;</span>]<br><span class="hljs-comment"># 连续纸</span><br>numeric_columns = [<span class="hljs-string">&#x27;age&#x27;</span>,<span class="hljs-string">&#x27;fare&#x27;</span>]<br>feature_columns =[]<br><span class="hljs-keyword">for</span> categorical_column <span class="hljs-keyword">in</span> categorical_columns:<br>    vocab = train_df[categorical_column].unique()<br>    feature_columns.append(<br>        tf.feature_column.indicator_column(<br>            tf.feature_column.categorical_column_with_vocabulary_list(<br>                categorical_column,vocab)))<br><span class="hljs-keyword">for</span> categorical_column <span class="hljs-keyword">in</span> numeric_columns:<br>    feature_columns.append(<br>        tf.feature_column.numeric_column(<br>            categorical_column,dtype=tf.float32<br>        )<br>    )<br><span class="hljs-comment"># 构件dataset的函数</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">make_dataset</span>(<span class="hljs-params">data_df,label_df,epochs=<span class="hljs-number">10</span>,shuffle=<span class="hljs-literal">True</span>,batch_size=<span class="hljs-number">32</span></span>):</span><br>    dataset = tf.data.Dataset.from_tensor_slices(<br>        (<span class="hljs-built_in">dict</span>(data_df),label_df)<br>    )<br>    <span class="hljs-keyword">if</span> shuffle:<br>        dataset =dataset.shuffle(<span class="hljs-number">10000</span>)<br>    dataset = dataset.repeat(epochs).batch(batch_size)<br>    <span class="hljs-keyword">return</span> dataset<br>train_dataset = make_dataset(train_df,y_train,batch_size=<span class="hljs-number">5</span>)<br><br><span class="hljs-comment"># keras.layers.DenseFeature</span><br>tf.keras.backend.set_floatx(<span class="hljs-string">&#x27;float64&#x27;</span>)<br><span class="hljs-comment"># for x,y in train_dataset.take(1):</span><br><span class="hljs-comment">#     age_column = feature_columns[7]</span><br><span class="hljs-comment">#     gender_column = feature_columns[0]</span><br><span class="hljs-comment">#     print(keras.layers.DenseFeatures(age_column)(x).numpy())  # 连续值不变</span><br><span class="hljs-comment">#     print(keras.layers.DenseFeatures(gender_column)(x).numpy())  # 离散值变为one-hot</span><br><span class="hljs-comment"># for x,y in train_dataset.take(1):</span><br><span class="hljs-comment">#     print(keras.layers.DenseFeatures(feature_columns)(x).numpy())</span><br><br>model = keras.models.Sequential([<br>    keras.layers.DenseFeatures(feature_columns),<br>    keras.layers.Dense(<span class="hljs-number">100</span>,activation=<span class="hljs-string">&quot;relu&quot;</span>),<br>    keras.layers.Dense(<span class="hljs-number">100</span>,activation=<span class="hljs-string">&quot;relu&quot;</span>),<br>    keras.layers.Dense(<span class="hljs-number">2</span>,activation=<span class="hljs-string">&quot;softmax&quot;</span>)<br>])<br>model.<span class="hljs-built_in">compile</span>(loss=<span class="hljs-string">&quot;sparse_categorical_crossentropy&quot;</span>,<br>              optimizer=keras.optimizers.SGD(lr=<span class="hljs-number">0.01</span>),<br>              metrics = [<span class="hljs-string">&#x27;accuracy&#x27;</span>])<br><span class="hljs-comment"># 1,model.fit</span><br><span class="hljs-comment"># 2.model--&gt;estimator -&gt;train</span><br><span class="hljs-comment"># 第一种</span><br><span class="hljs-comment"># train_dataset = make_dataset(train_df,y_train,epochs=100)</span><br><span class="hljs-comment"># eval_dataset = make_dataset(eval_df,y_eval,epochs=1,shuffle=False)</span><br><span class="hljs-comment"># model.fit(train_dataset,</span><br><span class="hljs-comment">#           validation_data = eval_dataset,</span><br><span class="hljs-comment">#           steps_per_epoch = 20,</span><br><span class="hljs-comment">#           validation_steps=8,</span><br><span class="hljs-comment">#           epochs=100)</span><br><span class="hljs-comment"># 第二种</span><br>estimator = keras.estimator.model_to_estimator(model)<br><span class="hljs-comment"># input_fn:函数或lambda  return  (feature,label)    或dataset---&gt;(feature,label)</span><br>estimator.train(input_fn = <span class="hljs-keyword">lambda</span> :make_dataset(train_df,y_train,epochs=<span class="hljs-number">100</span>))    <span class="hljs-comment"># 会出现bug</span><br></code></pre></td></tr></table></figure></li>
</ol>
</li>
<li><p>Tf.estimator.BaselineClassifier</p>
</li>
<li><p>Tf.estimator.LinerClassifier</p>
</li>
<li><p>Tf.estimator.DNNClassifier</p>
</li>
<li><p>Tf.feature_column</p>
<ol>
<li>categorical_column_with_vocabulary_list</li>
<li>numeric_column</li>
<li>indicator_column</li>
<li>cross_column</li>
</ol>
</li>
<li><p>keras.layers.DenseFeatures</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><code class="hljs python">train_file = <span class="hljs-string">&quot;csv/train.csv&quot;</span><br>eval_file = <span class="hljs-string">&quot;csv/eval.csv&quot;</span><br>train_df = pd.read_csv(train_file)  <span class="hljs-comment"># (627,9)</span><br>eval_df = pd.read_csv(eval_file)  <span class="hljs-comment"># (264.9)</span><br>y_train = train_df.pop(<span class="hljs-string">&quot;survived&quot;</span>)<br>y_eval = eval_df.pop(<span class="hljs-string">&quot;survived&quot;</span>)<br><br><br><span class="hljs-comment"># 离散值</span><br>categorical_columns = [<span class="hljs-string">&quot;sex&quot;</span>,<span class="hljs-string">&#x27;n_siblings_spouses&#x27;</span>,<span class="hljs-string">&#x27;parch&#x27;</span>,<span class="hljs-string">&#x27;class&#x27;</span>,<span class="hljs-string">&#x27;deck&#x27;</span>,<span class="hljs-string">&#x27;embark_town&#x27;</span>,<span class="hljs-string">&#x27;alone&#x27;</span>]<br><span class="hljs-comment"># 连续纸</span><br>numeric_columns = [<span class="hljs-string">&#x27;age&#x27;</span>,<span class="hljs-string">&#x27;fare&#x27;</span>]<br>feature_columns =[]<br><span class="hljs-keyword">for</span> categorical_column <span class="hljs-keyword">in</span> categorical_columns:<br>    vocab = train_df[categorical_column].unique()<br>    feature_columns.append(<br>        tf.feature_column.indicator_column(<br>            tf.feature_column.categorical_column_with_vocabulary_list(<br>                categorical_column,vocab)))<br><span class="hljs-keyword">for</span> categorical_column <span class="hljs-keyword">in</span> numeric_columns:<br>    feature_columns.append(<br>        tf.feature_column.numeric_column(<br>            categorical_column,dtype=tf.float32<br>        )<br>    )<br><span class="hljs-comment"># 构件dataset的函数</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">make_dataset</span>(<span class="hljs-params">data_df,label_df,epochs=<span class="hljs-number">10</span>,shuffle=<span class="hljs-literal">True</span>,batch_size=<span class="hljs-number">32</span></span>):</span><br>    dataset = tf.data.Dataset.from_tensor_slices(<br>        (<span class="hljs-built_in">dict</span>(data_df),label_df)<br>    )<br>    <span class="hljs-keyword">if</span> shuffle:<br>        dataset =dataset.shuffle(<span class="hljs-number">10000</span>)<br>    dataset = dataset.repeat(epochs).batch(batch_size)<br>    <span class="hljs-keyword">return</span> dataset<br><span class="hljs-comment"># =================</span><br><span class="hljs-comment"># output_dir = &quot;baseline_model&quot;</span><br><span class="hljs-comment"># if not os.path.exists(output_dir):</span><br><span class="hljs-comment">#     os.mkdir(output_dir)</span><br><span class="hljs-comment"># baseline_estimator = tf.estimator.BaselineClassifier(model_dir=output_dir,</span><br><span class="hljs-comment">#                                                      n_classes=2)</span><br><span class="hljs-comment"># baseline_estimator.train(input_fn=lambda :make_dataset(train_df,y_train,epochs=100))</span><br><span class="hljs-comment"># baseline_estimator.evaluate(input_fn=lambda :make_dataset(eval_df,y_eval,epochs=1,shuffle=False,batch_size=20))</span><br><span class="hljs-comment"># =================</span><br><span class="hljs-comment"># linear_output_dir = &quot;liner_model&quot;</span><br><span class="hljs-comment"># if not os.path.exists(linear_output_dir):</span><br><span class="hljs-comment">#     os.mkdir(linear_output_dir)</span><br><span class="hljs-comment"># linear_estimator = tf.estimator.LinearClassifier(</span><br><span class="hljs-comment">#     model_dir=linear_output_dir,</span><br><span class="hljs-comment">#     n_classes=2,</span><br><span class="hljs-comment">#     feature_columns=feature_columns</span><br><span class="hljs-comment"># )</span><br><span class="hljs-comment"># linear_estimator.train(input_fn=lambda :make_dataset(</span><br><span class="hljs-comment">#     train_df,y_train,epochs=100))</span><br><span class="hljs-comment"># =====================================</span><br>dnn_output_dir = <span class="hljs-string">&quot;dnn_model&quot;</span><br><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(dnn_output_dir):<br>    os.mkdir(dnn_output_dir)<br>dnn_estimator = tf.estimator.DNNClass ifier(<br>    model_dir=dnn_output_dir,<br>    n_classes=<span class="hljs-number">2</span>,<br>    feature_columns=feature_columns,<br>    hidden_units=[<span class="hljs-number">128</span>,<span class="hljs-number">128</span>], <span class="hljs-comment"># 两层,都是128</span><br>    activation_fn=tf.nn.relu,<br>    optimizer=<span class="hljs-string">&quot;Adam&quot;</span><br>)<br>dnn_estimator.train(input_fn= <span class="hljs-keyword">lambda</span> :make_dataset(train_df,y_train,epochs=<span class="hljs-number">100</span>))<br>dnn_estimator.evaluate(input_fn= <span class="hljs-keyword">lambda</span> :make_dataset(<br>    eval_df,y_eval,epochs=<span class="hljs-number">1</span>,shuffle=<span class="hljs-literal">False</span>))<br></code></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
</li>
<li><h1 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h1><ol>
<li><h3 id="知识点-3"><a href="#知识点-3" class="headerlink" title="知识点"></a>知识点</h3><ol>
<li><p>Tf框架:卷积实现</p>
<p>卷积网络:卷积+池化—全连接    ——&gt;分类任务</p>
<p>全卷积网络:去掉了最后的全连接层,变为反卷积层(是尺寸变大)   —–&gt;物体分割</p>
</li>
<li><p>项目:图像分类,kaggle 10monkeys,kaggle cifar10</p>
</li>
<li><p>理论:卷积,数据增强,迁移学习 </p>
</li>
<li><p>卷积网问题:</p>
<ol>
<li>参数太多<ol>
<li>局部连接,  图像区域性</li>
<li>参数共享 图像特征与位置无关</li>
</ol>
</li>
<li>池化时,剩余的数据会丢弃</li>
</ol>
</li>
</ol>
</li>
<li><h3 id="keras实现卷积神经网络"><a href="#keras实现卷积神经网络" class="headerlink" title="keras实现卷积神经网络"></a>keras实现卷积神经网络</h3><ol>
<li><p>```python</p>
<h1 id="coding-utf-8-1"><a href="#coding-utf-8-1" class="headerlink" title="coding:utf-8"></a>coding:utf-8</h1><h1 id="file-tf-keras-classification-model-cnn-py"><a href="#file-tf-keras-classification-model-cnn-py" class="headerlink" title="file: tf_keras_classification_model_cnn.py"></a>file: tf_keras_classification_model_cnn.py</h1><h1 id="author-Dean-1"><a href="#author-Dean-1" class="headerlink" title="author: Dean"></a>author: Dean</h1><h1 id="contact-49-x30-50-56-x39-54-56-57-51-57-x40-x71-x71-46-99-111-x6d"><a href="#contact-49-x30-50-56-x39-54-56-57-51-57-x40-x71-x71-46-99-111-x6d" class="headerlink" title="contact: &#49;&#x30;&#50;&#56;&#x39;&#54;&#56;&#57;&#51;&#57;&#x40;&#x71;&#x71;&#46;&#99;&#111;&#x6d;"></a>contact: <a href="mailto:&#49;&#x30;&#50;&#56;&#x39;&#54;&#56;&#57;&#51;&#57;&#x40;&#x71;&#x71;&#46;&#99;&#111;&#x6d;">&#49;&#x30;&#50;&#56;&#x39;&#54;&#56;&#57;&#51;&#57;&#x40;&#x71;&#x71;&#46;&#99;&#111;&#x6d;</a></h1><h1 id="time-2019-12-17-11-47-1"><a href="#time-2019-12-17-11-47-1" class="headerlink" title="time: 2019/12/17 11:47"></a>time: 2019/12/17 11:47</h1><h1 id="desc-深度神经网络"><a href="#desc-深度神经网络" class="headerlink" title="desc: 深度神经网络"></a>desc: 深度神经网络</h1><p>import matplotlib as mpl<br>import matplotlib.pyplot as plt<br>import numpy as np<br>import sklearn<br>import pandas as pd<br>import os,sys,time<br>import tensorflow as tf<br>from tensorflow import keras<br>def showVersion():</p>
<div class="code-wrapper"><pre><code class="hljs">print((tf.__version__))
print(sys.version_info)
for module in mpl, np, pd, sklearn, tf, keras:
    print(module.__name__,module.__version__)
</code></pre></div>
<h1 id="class-names-‘T-shirt’-’Trouser’-’Pullover’-’Dress’"><a href="#class-names-‘T-shirt’-’Trouser’-’Pullover’-’Dress’" class="headerlink" title="class_names = [‘T-shirt’,’Trouser’,’Pullover’,’Dress’,"></a>class_names = [‘T-shirt’,’Trouser’,’Pullover’,’Dress’,</h1><h1 id="‘Coat’-‘Sandal’-‘Shirt’-‘Sneaker’"><a href="#‘Coat’-‘Sandal’-‘Shirt’-‘Sneaker’" class="headerlink" title="‘Coat’, ‘Sandal’, ‘Shirt’, ‘Sneaker’,"></a>‘Coat’, ‘Sandal’, ‘Shirt’, ‘Sneaker’,</h1><h1 id="‘Bag’-‘Ankle-boot’"><a href="#‘Bag’-‘Ankle-boot’" class="headerlink" title="‘Bag’, ‘Ankle boot’"></a>‘Bag’, ‘Ankle boot’</h1><h1 id=""><a href="#" class="headerlink" title="]"></a>]</h1><p>fashion_mnist = keras.datasets.fashion_mnist<br>(x_train_all,y_train_all),(x_test,y_test) = fashion_mnist.load_data()<br>x_valid, x_train = x_train_all[:5000], x_train_all[5000:]<br>y_valid, y_train = y_train_all[:5000], y_train_all[5000:]</p>
<p>from sklearn.preprocessing import StandardScaler<br>scaler = StandardScaler()</p>
<p>x_train_scaled = scaler.fit_transform(x_train.astype(np.float32).reshape(-1,1)).reshape(-1,28,28,1)<br>x_valid_scaled = scaler.transform(x_valid.astype(np.float32).reshape(-1,1)).reshape(-1,28,28,1)  # 使用训练集的均值,方差<br>x_test_scaled = scaler.transform(x_test.astype(np.float32).reshape(-1,1)).reshape(-1,28,28,1)</p>
<p>def nn():</p>
<div class="code-wrapper"><pre><code class="hljs">model = keras.models.Sequential()
model.add(keras.layers.Conv2D(filters=32,  # 卷积核数量,
                              kernel_size=3,  # 大小
                              padding=&quot;same&quot;,  # 是否填充是的输入输出大小一样
                              activation=&quot;relu&quot;,  # 使用selu效果会更好
                              input_shape=(28,28,1)
                            ))
model.add(keras.layers.Conv2D(filters=32,kernel_size=3,
                              padding=&quot;same&quot;,
                              activation=&quot;relu&quot;))
model.add(keras.layers.MaxPool2D(pool_size=2))   # 一般步长与大小相同  pool 后的卷积层filter一般会翻倍
model.add(keras.layers.Conv2D(filters=64, kernel_size=3,
                              padding=&quot;same&quot;,
                              activation=&quot;relu&quot;))
model.add(keras.layers.Conv2D(filters=64, kernel_size=3,
                              padding=&quot;same&quot;,
                              activation=&quot;relu&quot;))
model.add(keras.layers.MaxPool2D(pool_size=2))
model.add(keras.layers.Conv2D(filters=128,kernel_size=3,
                              padding=&quot;same&quot;,
                              activation=&quot;relu&quot;))
model.add(keras.layers.Conv2D(filters=128, kernel_size=3,
                              padding=&quot;same&quot;,
                              activation=&quot;relu&quot;))
model.add(keras.layers.MaxPool2D(pool_size=2))
model.add(keras.layers.Flatten())  # 将输入一维化
model.add(keras.layers.Dense(128,activation=&quot;relu&quot;))
model.add(keras.layers.Dense(10,activation=&quot;softmax&quot;))
model.summary()
model.compile(loss=&quot;sparse_categorical_crossentropy&quot;,
              optimizer = &quot;adam&quot;,
              metrics = [&#39;accuracy&#39;])
logdir = &quot;cnn-callbacks&quot;
if not os.path.exists(logdir):
    os.mkdir(logdir)
output_model_file = os.path.join(logdir,&quot;fashion_mnist_model.h5&quot;)
callbacks = [
    keras.callbacks.TensorBoard(logdir),
    keras.callbacks.ModelCheckpoint(output_model_file,save_best_only = True),
    keras.callbacks.EarlyStopping(patience = 5, min_delta = 1e-3)
]
history = model.fit(x_train_scaled,y_train,epochs=10,
                    validation_data=(x_valid_scaled,y_valid),
                    callbacks = callbacks)
model.evaluate(x_test_scaled,y_test)  # 验证集验证
return history
</code></pre></div>
<p>def plot_learning_curves(history):</p>
<div class="code-wrapper"><pre><code class="hljs">pd.DataFrame(history.history).plot(figsize=(8,5))
plt.grid(True)
plt.gca().set_ylim(0,3)
plt.show()
</code></pre></div>
<p>if <strong>name</strong> ==”<strong>main</strong>“:</p>
<div class="code-wrapper"><pre><code class="hljs">history = nn()
plot_learning_curves(history)
</code></pre></div>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs awk"><br>      <br><br><span class="hljs-number">3</span>. keras实现深度可分离卷积<br><br>   <span class="hljs-number">1</span>.  标准卷积 <br><br>      <span class="hljs-number">1</span>. 卷积核大小(<span class="hljs-variable">$D_k</span>$)<br><br>      <span class="hljs-number">2</span>. 卷积核输入通道数M<br><br>      <span class="hljs-number">3</span>. 卷积核个数N,输出通道N<br><br>      <span class="hljs-number">4</span>. 图像大小$(D_F)$<br><br>         <span class="hljs-variable">$D_k</span>*D_k*M*N*D_F*D_F$<br><br>   <span class="hljs-number">2</span>. 深度可分离卷积<br><br>      (此时的卷积核输入时原图n\*n\*<span class="hljs-number">3</span>,卷积核为k\*k\*<span class="hljs-number">1</span>,为了计算原图所有通道,该卷积核个数就是输入通道数M)	<span class="hljs-variable">$D_k</span>*D_k*<span class="hljs-number">1</span>*M*D_F*D_F+<span class="hljs-number">1</span>*<span class="hljs-number">1</span>*M*N*D_F*D_F$ <br><br>      参考:<br><br>      https:<span class="hljs-regexp">//</span>blog.csdn.net<span class="hljs-regexp">/xiewenbo/</span>article<span class="hljs-regexp">/details/</span><span class="hljs-number">84315560</span><br><br>      https:<span class="hljs-regexp">//</span>blog.csdn.net<span class="hljs-regexp">/qq_21997625/</span>article<span class="hljs-regexp">/details/</span><span class="hljs-number">87106152</span><br><br>   <span class="hljs-number">3</span>. ```python<br>       <span class="hljs-comment"># 代码同上</span><br>       <span class="hljs-comment"># 第一个Conv2D不变</span><br>       <span class="hljs-comment"># 其余的Conv2D修改为SeparableConv2D即可</span><br>       <span class="hljs-comment">#  计算量少</span><br>         <br>      <span class="hljs-comment"># 两层 3*3 视野域就是 一个5*5</span><br>      <br>      <span class="hljs-comment"># 计算量几乎缩小n倍</span><br>      <br>      <span class="hljs-comment"># 深度可分离卷积</span><br>      <br></code></pre></td></tr></table></figure>

<p><img src="https://img2018.cnblogs.com/blog/1333782/201912/1333782-20191223173158408-1473862527.png" srcset="/img/loading.gif" lazyload></p>
</li>
</ol>
</li>
</ol>
</li>
</ol>
<ol start="4">
<li><p>kera实战kaggle</p>
<ol>
<li><p>10 monkey,cifar10</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># coding:utf-8</span><br><span class="hljs-comment"># file: 1_10_monkey_model.py</span><br><span class="hljs-comment"># author: Dean</span><br><span class="hljs-comment"># contact: 1028968939@qq.com</span><br><span class="hljs-comment"># time: 2019/12/23 11:30</span><br><span class="hljs-comment"># desc: keras_generator 搭建模型</span><br><span class="hljs-comment">#    model.fit  将数据放入内存训练</span><br><span class="hljs-comment">#    model.fit_generator   处理大数据,  使用生成器的数据集</span><br><br><span class="hljs-keyword">import</span> matplotlib <span class="hljs-keyword">as</span> mpl<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> sklearn<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> os,sys,time<br><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">from</span> tensorflow <span class="hljs-keyword">import</span> keras<br><br><br>train_dir=<span class="hljs-string">r&quot;I:\人工智能数据\10_monkey\training\training&quot;</span><br>valid_dir=<span class="hljs-string">r&quot;I:\人工智能数据\10_monkey\validation\validation&quot;</span><br>label_txt=<span class="hljs-string">r&quot;I:\人工智能数据\10_monkey\monkey_labels.txt&quot;</span><br><br>labels = pd.read_csv(label_txt,header=<span class="hljs-number">0</span>)<br><br>height = <span class="hljs-number">128</span>  <span class="hljs-comment"># 缩放大小</span><br>width = <span class="hljs-number">128</span><br>channels = <span class="hljs-number">3</span><br>batch_size = <span class="hljs-number">64</span><br>num_classes = <span class="hljs-number">10</span><br><br><span class="hljs-comment"># keras中的数据集:读取数据,数据分享</span><br><br>train_datagen = keras.preprocessing.image.ImageDataGenerator(<br>    rescale = <span class="hljs-number">1.</span>/<span class="hljs-number">255</span>,  <span class="hljs-comment"># 像素点缩放到0-1</span><br>    rotation_range = <span class="hljs-number">40</span>,  <span class="hljs-comment"># 图片增强方式,随机旋转40</span><br>    width_shift_range = <span class="hljs-number">0.2</span>,  <span class="hljs-comment"># 偏移</span><br>    height_shift_range = <span class="hljs-number">0.2</span>,  <span class="hljs-comment">#</span><br>    shear_range = <span class="hljs-number">0.2</span>,  <span class="hljs-comment"># 剪切强度</span><br>    zoom_range = <span class="hljs-number">0.2</span>,  <span class="hljs-comment"># 缩放程度</span><br>    horizontal_flip = <span class="hljs-literal">True</span>,  <span class="hljs-comment"># 水平翻转</span><br>    fill_mode = <span class="hljs-string">&quot;nearest&quot;</span>,  <span class="hljs-comment"># 放大时填充像素,选择最近的填充</span><br>)<br><br><span class="hljs-comment"># 读取图片,按照上边方法进行处理</span><br>train_generator = train_datagen.flow_from_directory(train_dir,<br>                                                    target_size=(height,width),<br>                                                    batch_size=batch_size,<br>                                                    seed=<span class="hljs-number">7</span>,  <span class="hljs-comment"># 随机数</span><br>                                                    shuffle=<span class="hljs-literal">True</span>,<br>                                                    class_mode=<span class="hljs-string">&quot;categorical&quot;</span>)  <span class="hljs-comment"># label格式 one-hot</span><br>valid_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=<span class="hljs-number">1.</span>/<span class="hljs-number">255</span>)<br>valid_generator = valid_datagen.flow_from_directory(valid_dir,<br>                                                    target_size=(height,width),<br>                                                    batch_size=batch_size,<br>                                                    seed=<span class="hljs-number">7</span>,<br>                                                    shuffle=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># 不用训练不用打乱</span><br>                                                    class_mode=<span class="hljs-string">&quot;categorical&quot;</span>)<br>train_num = train_generator.samples<br>valid_num = valid_generator.samples<br><span class="hljs-comment"># print(train_num,valid_num) #  1098 272</span><br><span class="hljs-comment"># x,y = train_generator.next()  # (64,128,128,3) (64,10)</span><br><br>model = keras.models.Sequential([<br>    keras.layers.Conv2D(filters=<span class="hljs-number">32</span>,kernel_size=<span class="hljs-number">3</span>,padding=<span class="hljs-string">&quot;same&quot;</span>,<br>                        activation=<span class="hljs-string">&quot;relu&quot;</span>,input_shape=(width,height,channels)),<br>    keras.layers.Conv2D(filters=<span class="hljs-number">32</span>,kernel_size=<span class="hljs-number">3</span>,padding=<span class="hljs-string">&quot;same&quot;</span>,<br>                        activation=<span class="hljs-string">&quot;relu&quot;</span>),<br>    keras.layers.MaxPool2D(pool_size=<span class="hljs-number">2</span>),<br>    keras.layers.Conv2D(filters=<span class="hljs-number">64</span>,kernel_size=<span class="hljs-number">3</span>,padding=<span class="hljs-string">&quot;same&quot;</span>,<br>                        activation=<span class="hljs-string">&quot;relu&quot;</span>),<br>    keras.layers.Conv2D(filters=<span class="hljs-number">64</span>,kernel_size=<span class="hljs-number">3</span>,padding=<span class="hljs-string">&quot;same&quot;</span>,<br>                        activation=<span class="hljs-string">&quot;relu&quot;</span>),<br>    keras.layers.MaxPool2D(pool_size=<span class="hljs-number">2</span>),<br>    keras.layers.Conv2D(filters=<span class="hljs-number">128</span>,kernel_size=<span class="hljs-number">3</span>,padding=<span class="hljs-string">&quot;same&quot;</span>,<br>                        activation=<span class="hljs-string">&quot;relu&quot;</span>),<br>    keras.layers.Conv2D(filters=<span class="hljs-number">128</span>,kernel_size=<span class="hljs-number">3</span>,padding=<span class="hljs-string">&quot;same&quot;</span>,<br>                        activation=<span class="hljs-string">&quot;relu&quot;</span>),<br>    keras.layers.MaxPool2D(pool_size=<span class="hljs-number">2</span>),<br>    keras.layers.Flatten(),<br>    keras.layers.Dense(<span class="hljs-number">128</span>,activation=<span class="hljs-string">&quot;relu&quot;</span>),<br>    keras.layers.Dense(num_classes,activation=<span class="hljs-string">&quot;softmax&quot;</span>)<br>])<br>model.<span class="hljs-built_in">compile</span>(loss=<span class="hljs-string">&quot;categorical_crossentropy&quot;</span>,<br>              optimizer=<span class="hljs-string">&quot;adam&quot;</span>,metrics=[<span class="hljs-string">&#x27;accuracy&#x27;</span>])<br>model.summary()<br><br>epochs = <span class="hljs-number">300</span><br><span class="hljs-comment"># 最后acc 97% 98%</span><br>history = model.fit_generator(train_generator,<br>                              steps_per_epoch= train_num//batch_size,<br>                              epochs = epochs,<br>                              validation_data=valid_generator,<br>                              validation_steps= valid_num//batch_size)<br><span class="hljs-comment"># history.history.keys()  # loss,acc, val_loss,val_acc</span><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_learning_curves</span>(<span class="hljs-params">history,label,epochs,min_value,max_value</span>):</span><br>    data=&#123;&#125;<br>    data[label] = history.history[label]<br>    data[<span class="hljs-string">&quot;val_&quot;</span>+label]=history.history[<span class="hljs-string">&quot;val_&quot;</span>+label]<br>    pd.DataFrame(data).plot(figsize=(<span class="hljs-number">8.5</span>))<br>    plt.grid(<span class="hljs-literal">True</span>)<br>    plt.axis([<span class="hljs-number">0</span>,epochs,min_value,max_value])<br>    plt.show()<br>plot_learning_curves(history,<span class="hljs-string">&quot;acc&quot;</span>,epochs,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>)<br>plot_learning_curves(history,<span class="hljs-string">&quot;loss&quot;</span>,epochs,<span class="hljs-number">1.5</span>,<span class="hljs-number">2.5</span>)<br></code></pre></td></tr></table></figure></li>
<li><p>数据增强(调整数据 提高准确率)与迁移学习</p>
<ol>
<li>```python<h1 id="model-部分修改即可"><a href="#model-部分修改即可" class="headerlink" title="model 部分修改即可"></a>model 部分修改即可</h1>resnet50_fine_tune = keras.models.Sequential();<br>resnet50_fine_tune.add(keras.applications.ResNet50(include_top=False,   # 不包含最后一层<div class="code-wrapper"><pre><code class="hljs">                                               pooling = &#39;avg&#39;,
                                               weights=&quot;imagenet&quot;))  # None 从头开始,imagenet接着
</code></pre></div>
resnet50_fine_tune.add(keras.layers.Dense(num_classes,activation=”softmax”))<br>resnet50_fine_tune.layers[0].trainable= False  # 设置第一层的参数不调整<br>“””<br>resnet50 = keras.applications.ResNet50(include_top=False,<div class="code-wrapper"><pre><code class="hljs">                                   pooling=&quot;avg&quot;,
                                   weights=&quot;imagenet&quot;)
</code></pre></div>
resnet50.summary()<br>for layer in resnet50.layers[0:-5]:  # 设置resnet50中后0–5层也不可训练,其余可训练<div class="code-wrapper"><pre><code class="hljs">layer.trainable=False
</code></pre></div>
resnet50_new = keras.models.Sequential([<div class="code-wrapper"><pre><code class="hljs">resnet50,
keras.layers.Dense(num_classes,activation=&quot;softmax&quot;),
</code></pre></div>
])<br>“””<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br></pre></td><td class="code"><pre><code class="hljs python">      <br>```python<br><span class="hljs-comment"># coding:utf-8</span><br><span class="hljs-comment"># file: 1_cifar10_model.py</span><br><span class="hljs-comment"># author: Dean</span><br><span class="hljs-comment"># contact: 1028968939@qq.com</span><br><span class="hljs-comment"># time: 2019/12/23 11:30</span><br><span class="hljs-comment"># desc:</span><br><span class="hljs-keyword">import</span> matplotlib <span class="hljs-keyword">as</span> mpl<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> sklearn<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> os,sys,time<br><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">from</span> tensorflow <span class="hljs-keyword">import</span> keras<br><span class="hljs-comment"># data https://www.kaggle.com/c/cifar-10/data</span><br>class_names = [<br>    <span class="hljs-string">&#x27;airplane&#x27;</span>,<br>    <span class="hljs-string">&#x27;automobile&#x27;</span>,<br>    <span class="hljs-string">&#x27;bird&#x27;</span>,<br>    <span class="hljs-string">&#x27;cat&#x27;</span>,<br>    <span class="hljs-string">&#x27;deer&#x27;</span>,<br>    <span class="hljs-string">&#x27;dog&#x27;</span>,<br>    <span class="hljs-string">&#x27;frog&#x27;</span>,<br>    <span class="hljs-string">&#x27;horse&#x27;</span>,<br>    <span class="hljs-string">&#x27;ship&#x27;</span>,<br>    <span class="hljs-string">&#x27;truck&#x27;</span><br>]<br>train_lables_file = <span class="hljs-string">r&#x27;I:\人工智能数据\cifar10\trainLabels.csv&#x27;</span><br>test_csv_file = <span class="hljs-string">r&#x27;I:\人工智能数据\cifar10\sampleSubmission.csv&#x27;</span><br>train_folder = <span class="hljs-string">r&#x27;I:\人工智能数据\cifar10\train&#x27;</span><br>test_floder = <span class="hljs-string">r&#x27;I:\人工智能数据\cifar10\test&#x27;</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse_csv_file</span>(<span class="hljs-params">filepath,folder</span>):</span><br>    <span class="hljs-string">&quot;&quot;&quot;Paeses csv files into (filename(path),label) format  (xxx.png,&#x27;cat&#x27;)&quot;&quot;&quot;</span><br>    results =[]<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(filepath,<span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:<br>        lines = f.readlines()[<span class="hljs-number">1</span>:]  <span class="hljs-comment"># 去掉header</span><br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> lines:<br>            image_id,label_str = line.strip(<span class="hljs-string">&quot;\n&quot;</span>).split(<span class="hljs-string">&#x27;,&#x27;</span>)<br>            image_full_path = os.path.join(folder,image_id+<span class="hljs-string">&quot;.png&quot;</span>)<br>            results.append((image_full_path,label_str))<br>    <span class="hljs-keyword">return</span> results<br>train_lables_info = parse_csv_file(train_lables_file,train_folder)  <span class="hljs-comment"># 50000</span><br>test_csv_info = parse_csv_file(test_csv_file,test_floder)  <span class="hljs-comment"># 300000</span><br><br><span class="hljs-comment"># 制作dataframe</span><br><span class="hljs-comment"># train_df = pd.DataFrame(train_lables_info)</span><br>train_df = pd.DataFrame(train_lables_info[<span class="hljs-number">0</span>:<span class="hljs-number">45000</span>])<br>valid_df = pd.DataFrame(train_lables_info[<span class="hljs-number">45000</span>:])<br>test_df = pd.DataFrame(test_csv_info)<br><br><span class="hljs-comment"># 设置dataframe的列名</span><br>train_df.columns = [<span class="hljs-string">&quot;filepath&quot;</span>,<span class="hljs-string">&#x27;class&#x27;</span>]<br>valid_df.columns = [<span class="hljs-string">&quot;filepath&quot;</span>,<span class="hljs-string">&#x27;class&#x27;</span>]<br>test_df.columns = [<span class="hljs-string">&quot;filepath&quot;</span>,<span class="hljs-string">&#x27;class&#x27;</span>]<br><br><br>height = <span class="hljs-number">32</span>  <span class="hljs-comment"># 缩放大小</span><br>width = <span class="hljs-number">32</span><br>channels = <span class="hljs-number">3</span><br>batch_size = <span class="hljs-number">32</span><br>num_classes = <span class="hljs-number">10</span><br><br><span class="hljs-comment"># keras中的数据集:读取数据,数据分享</span><br><br>train_datagen = keras.preprocessing.image.ImageDataGenerator(<br>    rescale = <span class="hljs-number">1.</span>/<span class="hljs-number">255</span>,  <span class="hljs-comment"># 像素点缩放到0-1</span><br>    rotation_range = <span class="hljs-number">40</span>,  <span class="hljs-comment"># 图片增强方式,随机旋转40</span><br>    width_shift_range = <span class="hljs-number">0.2</span>,  <span class="hljs-comment"># 偏移</span><br>    height_shift_range = <span class="hljs-number">0.2</span>,  <span class="hljs-comment">#</span><br>    shear_range = <span class="hljs-number">0.2</span>,  <span class="hljs-comment"># 剪切强度</span><br>    zoom_range = <span class="hljs-number">0.2</span>,  <span class="hljs-comment"># 缩放程度</span><br>    horizontal_flip = <span class="hljs-literal">True</span>,  <span class="hljs-comment"># 水平翻转</span><br>    fill_mode = <span class="hljs-string">&quot;nearest&quot;</span>,  <span class="hljs-comment"># 放大时填充像素,选择最近的填充</span><br>)<br><br><span class="hljs-comment"># 读取图片,按照上边方法进行处理</span><br>train_generator = train_datagen.flow_from_dataframe(<br>    train_df,<br>    directory=<span class="hljs-string">&quot;./&quot;</span>,<br>    x_col=<span class="hljs-string">&quot;filepath&quot;</span>,<br>    y_col=<span class="hljs-string">&quot;class&quot;</span>,<br>    classes=class_names,<br>    target_size=(height, width),<br>    batch_size=batch_size,<br>    seed=<span class="hljs-number">7</span>,<br>    shuffle=<span class="hljs-literal">True</span>,<br>    class_mode=<span class="hljs-string">&quot;sparse&quot;</span><br>)<br>valid_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=<span class="hljs-number">1.</span>/<span class="hljs-number">255</span>)<br>valid_generator = valid_datagen.flow_from_dataframe(valid_df,<br>                                                    directory=<span class="hljs-string">&quot;./&quot;</span>,<br>                                                    x_col=<span class="hljs-string">&quot;filepath&quot;</span>,<br>                                                    y_col=<span class="hljs-string">&quot;class&quot;</span>,<br>                                                    classes=class_names,<br>                                                    target_size=(height,width),<br>                                                    batch_size=batch_size,<br>                                                    seed=<span class="hljs-number">7</span>,<br>                                                    shuffle=<span class="hljs-literal">False</span>,<br>                                                    class_mode=<span class="hljs-string">&quot;sparse&quot;</span>)<br>train_num = train_generator.samples<br>valid_num = valid_generator.samples<br><span class="hljs-comment"># print(train_num,valid_num) #  1098 272</span><br><span class="hljs-comment"># x,y = train_generator.next()  # (64,128,128,3) (64,10)</span><br><br>model = keras.models.Sequential([<br>    keras.layers.Conv2D(filters=<span class="hljs-number">128</span>,kernel_size=<span class="hljs-number">3</span>,padding=<span class="hljs-string">&quot;same&quot;</span>,<br>                        activation=<span class="hljs-string">&quot;relu&quot;</span>,input_shape=(width,height,channels)),<br>    keras.layers.BatchNormalization(),<br>    keras.layers.Conv2D(filters=<span class="hljs-number">128</span>,kernel_size=<span class="hljs-number">3</span>,padding=<span class="hljs-string">&quot;same&quot;</span>,<br>                        activation=<span class="hljs-string">&quot;relu&quot;</span>),<br>    keras.layers.BatchNormalization(),<br>    keras.layers.MaxPool2D(pool_size=<span class="hljs-number">2</span>),<br>    keras.layers.Conv2D(filters=<span class="hljs-number">256</span>,kernel_size=<span class="hljs-number">3</span>,padding=<span class="hljs-string">&quot;same&quot;</span>,<br>                        activation=<span class="hljs-string">&quot;relu&quot;</span>),<br>    keras.layers.BatchNormalization(),<br>    keras.layers.Conv2D(filters=<span class="hljs-number">256</span>,kernel_size=<span class="hljs-number">3</span>,padding=<span class="hljs-string">&quot;same&quot;</span>,<br>                        activation=<span class="hljs-string">&quot;relu&quot;</span>),<br>    keras.layers.BatchNormalization(),<br>    keras.layers.MaxPool2D(pool_size=<span class="hljs-number">2</span>),<br>    keras.layers.Conv2D(filters=<span class="hljs-number">512</span>,kernel_size=<span class="hljs-number">3</span>,padding=<span class="hljs-string">&quot;same&quot;</span>,<br>                        activation=<span class="hljs-string">&quot;relu&quot;</span>),<br>    keras.layers.BatchNormalization(),<br>    keras.layers.Conv2D(filters=<span class="hljs-number">512</span>,kernel_size=<span class="hljs-number">3</span>,padding=<span class="hljs-string">&quot;same&quot;</span>,<br>                        activation=<span class="hljs-string">&quot;relu&quot;</span>),<br>    keras.layers.BatchNormalization(),<br>    keras.layers.MaxPool2D(pool_size=<span class="hljs-number">2</span>),<br>    keras.layers.Flatten(),<br>    keras.layers.Dense(<span class="hljs-number">512</span>,activation=<span class="hljs-string">&quot;relu&quot;</span>),<br>    keras.layers.Dense(num_classes,activation=<span class="hljs-string">&quot;softmax&quot;</span>)<br>])<br>model.<span class="hljs-built_in">compile</span>(loss=<span class="hljs-string">&quot;sparse_categorical_crossentropy&quot;</span>,<br>              optimizer=<span class="hljs-string">&quot;adam&quot;</span>,metrics=[<span class="hljs-string">&#x27;accuracy&#x27;</span>])<br>model.summary()<br><br>epochs = <span class="hljs-number">1</span><br>history = model.fit_generator(train_generator,<br>                              steps_per_epoch= train_num//batch_size,<br>                              epochs = epochs,<br>                              validation_data=valid_generator,<br>                              validation_steps= valid_num//batch_size)<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_learning_curves</span>(<span class="hljs-params">history,label,epochs,min_value,max_value</span>):</span><br>    data=&#123;&#125;<br>    data[label] = history.history[label]<br>    data[<span class="hljs-string">&quot;val_&quot;</span>+label]=history.history[<span class="hljs-string">&quot;val_&quot;</span>+label]<br>    pd.DataFrame(data).plot(figsize=(<span class="hljs-number">8.5</span>))<br>    plt.grid(<span class="hljs-literal">True</span>)<br>    plt.axis([<span class="hljs-number">0</span>,epochs,min_value,max_value])<br>    plt.show()<br>plot_learning_curves(history,<span class="hljs-string">&quot;acc&quot;</span>,epochs,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>)<br>plot_learning_curves(history,<span class="hljs-string">&quot;loss&quot;</span>,epochs,<span class="hljs-number">0</span>,<span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
</li>
<li><h1 id="循环神经网络"><a href="#循环神经网络" class="headerlink" title="循环神经网络"></a>循环神经网络</h1><ol>
<li>Tf框架:LSTM实现</li>
<li>项目:文本分类,文本生成,Kaggle文本分类</li>
<li>理论:序列式问题,循环网络,LSTM,双向LSTM</li>
</ol>
</li>
<li><h1 id="Tensorflow分布式"><a href="#Tensorflow分布式" class="headerlink" title="Tensorflow分布式"></a>Tensorflow分布式</h1><ol>
<li><h3 id="理论部分"><a href="#理论部分" class="headerlink" title="理论部分"></a>理论部分</h3><ol>
<li>GPU设置<ol>
<li>默认用全部GPU并占满内存</li>
<li>如何不浪费内存和计算资源<ol>
<li>内存增长</li>
<li>虚拟设备机制</li>
</ol>
</li>
<li>多GPU<ol>
<li>虚拟GPU&amp;实际GPU</li>
<li>手工设置&amp;分布式机制</li>
</ol>
</li>
<li>API<ol>
<li>tfdebugging.set_log_device_placement</li>
<li>tf.config.experimental.set_visible_devices  设置可见设备</li>
<li>tf.config.experimental.list_logical_devices  获取逻辑设备</li>
<li>tf.config.experimental.list_physical_devices  获取物理设备</li>
<li>tf.config.experimental.set_memory——growth 设置内存自增</li>
<li>tf.config.experimental.VirtualDeviceConfiguration 建立逻辑设备</li>
<li>tf.config.set_soft_device_placement 自动分配任务到设备</li>
</ol>
</li>
</ol>
</li>
<li>分布式策略</li>
</ol>
</li>
<li><h3 id="实战部分"><a href="#实战部分" class="headerlink" title="实战部分"></a>实战部分</h3><ol>
<li>GPU设置部分</li>
<li>分布式训练</li>
</ol>
</li>
</ol>
</li>
<li><h1 id="Tensorflow模型保存于部署"><a href="#Tensorflow模型保存于部署" class="headerlink" title="Tensorflow模型保存于部署"></a>Tensorflow模型保存于部署</h1><ol>
<li><p>Tf框架:模型保存,导出tflite,部署</p>
</li>
<li><p>项目:图像分类</p>
<p><img src="https://img2018.cnblogs.com/blog/1333782/201912/1333782-20191223173240250-502999884.png" srcset="/img/loading.gif" lazyload></p>
</li>
</ol>
</li>
</ol>
<div class="code-wrapper"><pre><code class="hljs">  ![](https://img2018.cnblogs.com/blog/1333782/201912/1333782-20191223173249312-1525127491.png)
</code></pre></div>
<ol start="3">
<li><h3 id="模型保存"><a href="#模型保存" class="headerlink" title="模型保存"></a>模型保存</h3><ol>
<li><h4 id="文件格式"><a href="#文件格式" class="headerlink" title="文件格式"></a>文件格式</h4><ol>
<li>Ckeckpoint与graphdef (tf1.0)</li>
<li>keras(hdf5),SavedModel(tf2.0)(参数+网络结构)</li>
</ol>
</li>
<li><h4 id="保存的是什么"><a href="#保存的是什么" class="headerlink" title="保存的是什么"></a>保存的是什么</h4><ol>
<li>参数</li>
<li>参数+网络结构</li>
</ol>
</li>
<li><h4 id="TFLite"><a href="#TFLite" class="headerlink" title="TFLite"></a>TFLite</h4><ol>
<li>TFLite Converter<ol>
<li>模型转化  将上边的三种模型转化为tflite</li>
</ol>
</li>
<li>TFLite Interpreter<ol>
<li>模型加载</li>
<li>支持android与ios</li>
<li>支持多种语言</li>
</ol>
</li>
<li>TFLite-FlatBuffer<ol>
<li>google开源的跨平台数据序列化库</li>
<li>优点<ol>
<li>直接读取序列化数据</li>
<li>高效内存使用和速度</li>
<li>灵活,数据前后向兼容,灵活控制数据结构</li>
<li>代码少</li>
<li>强类型数据</li>
</ol>
</li>
</ol>
</li>
<li>TFlite-量化<ol>
<li>参数从float变为8bit整数<ol>
<li>准确率损失</li>
<li>模型大小变为1/4</li>
</ol>
</li>
<li>量化方法<ol>
<li>float=(int-归零点)*因子</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li><h3 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h3><p><img src="https://img2018.cnblogs.com/blog/1333782/201912/1333782-20191223173305270-1255044464.png" srcset="/img/loading.gif" lazyload></p>
</li>
</ol>
</li>
</ol>
<div class="code-wrapper"><pre><code class="hljs">     1. keras-保存参数与保存模型+参数

        <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><pre><code class="hljs python">keras.callbacks.ModelCheckpoint(out_put_dir,<br>                               save_best_only=<span class="hljs-literal">True</span>,<br>                               save_weights_only=<span class="hljs-literal">False</span>) <span class="hljs-comment"># 为false表示只保存参数,True表示都保存</span><br>keras.models.load_model(out_put_dir) <span class="hljs-comment"># 若都保存了,从新加载后和可直接使用</span><br></code></pre></td></tr></table></figure>

        <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 定义模型之后,导入weights 可使用</span><br></code></pre></td></tr></table></figure>

        <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 也可保存权重</span><br>model.save_weights(<span class="hljs-string">&quot;xxxx/xxx.h5&quot;</span>) <br></code></pre></td></tr></table></figure>

        <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">tf.saved_model.save(model,<span class="hljs-string">&quot;.../xxx_garph&quot;</span>)<br><span class="hljs-comment"># assets</span><br><span class="hljs-comment"># variables checkpoint 信息</span><br><span class="hljs-comment"># saved_model.pb </span><br></code></pre></td></tr></table></figure>

        <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 命令行工具查看model信息</span><br>!saved_model_cli show --<span class="hljs-built_in">dir</span> <span class="hljs-string">&quot;path&quot;</span> --<span class="hljs-built_in">all</span><br><span class="hljs-comment"># 载入model</span><br>model = tf.saved_model.load(<span class="hljs-string">&quot;path&quot;</span>)<br>inference = model.signatures[<span class="hljs-string">&quot;serving_default&quot;</span>]<br>results = inference(tf.constant(x_test_scaled[<span class="hljs-number">0</span>:<span class="hljs-number">1</span>]))<br></code></pre></td></tr></table></figure>

        

     2. keras签名函数保存到SavedModel

        <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">tf_export =tf.Model()<br>tf_export.cube = 签名函数<br>tf.saved_model.save(tf._export,<span class="hljs-built_in">dir</span>)<br></code></pre></td></tr></table></figure>

     3. keras,SavedModel,签名函数到具体函数

        <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">load_saved_model=keras.models.load_model(<span class="hljs-string">&quot;.../...h5&quot;</span>)<br>load_saved_model(np.zeros([<span class="hljs-number">1</span>,<span class="hljs-number">28</span>,<span class="hljs-number">28</span>]))<br><br>run_model = tf.function(<span class="hljs-keyword">lambda</span> x:load_saved_model(x))<br>keras_concrete_function = run_model.get_concrete_function(<br>    tf.TensorSpec(<br>    	load_keras_model.inputs[<span class="hljs-number">0</span>].shape,<br>        load_keras_model.inputs[<span class="hljs-number">0</span>].dtype<br>    ))<br><span class="hljs-comment"># 测试</span><br>keras_concrete_function(tf.constant(np.zeros(<span class="hljs-number">1</span>,<span class="hljs-number">28</span>,<span class="hljs-number">28</span>,dtype=np.float32)))<br></code></pre></td></tr></table></figure>

     4. keras,SavedModel,具体函数到tflite

     5. tflite量化

     6. tensorflow js.android部署
</code></pre>
<ol start="10">
<li><h1 id="机器翻译于tensorflow2tensor使用"><a href="#机器翻译于tensorflow2tensor使用" class="headerlink" title="机器翻译于tensorflow2tensor使用"></a>机器翻译于tensorflow2tensor使用</h1><ol>
<li>Tf框架:transformer实现,tensor2tensor使用</li>
<li>项目:机器翻译</li>
<li>理论:序列道序列模型.注意力机制,可缩放点积注意力,多头注意力</li>
</ol>
</li>
</ol>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/01/16/cnblog/Tensorflow%E6%97%A5%E5%BF%97%E6%A0%BC%E5%BC%8F/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile"></span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/01/16/cnblog/Tensorflow2.0-%E5%9F%BA%E7%A1%80/">
                        <span class="hidden-mobile"></span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  

  

  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  <script  src="/js/local-search.js" ></script>



  
    <script  src="/js/img-lazyload.js" ></script>
  



  



  
    <script  src="https://cdn.jsdelivr.net/npm/tocbot@4/dist/tocbot.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4/anchor.min.js" ></script>
  
  
    <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js" ></script>
  






  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
        typing(title);
      
    })(window, document);
  </script>















<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


</body>
</html>
